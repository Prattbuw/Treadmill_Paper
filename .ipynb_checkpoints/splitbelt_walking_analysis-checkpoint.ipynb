{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of walking on the split-belt treadmill\n",
    "## Brandon Pratt\n",
    "\n",
    "Characterize body posture, step kinematics, and interlimb coordination of flies walking on the split-belt treadmill.\n",
    "\n",
    "The datasets analyzed by this analysis script can be access at this Dryad repository: https://doi.org/10.5061/dryad.mpg4f4r73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import math\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sea\n",
    "import scipy.signal\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import vonmises\n",
    "from scipy.signal import hilbert\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy import interpolate\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize tracked body and leg positions\n",
    "\n",
    "Also, align the fly to a common heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def org_data(DF, Rx, Ry, Rz):\n",
    "    df=DF\n",
    "    headers = df.columns.values.tolist() # column headers\n",
    "    fc = np.median(df[headers[0:3]].values, axis = 0)\n",
    "    bc = np.median(df[headers[6:9]].values, axis = 0)\n",
    "    chamber_length = np.sqrt((fc[0] - bc[0])**2 + (fc[1] - bc[1])**2 + (fc[2] - bc[2])**2)\n",
    "    # determine if there needs to be a correction factor\n",
    "    true_chamber_length=8.929 # known chamber length\n",
    "    #     chamber_length=2.255\n",
    "    correction_val=true_chamber_length/chamber_length # convert the tracked positions to actual positions \n",
    "    \n",
    "    # determine division boundary value between the left and right belts\n",
    "    df=curr_tracked_data\n",
    "    bcc_mat = np.matrix(df[headers[12:15]][:]) # use y position of the back of the chamber as a proxy for the division between the belts\n",
    "    transformed_bcc_mat = np.transpose(np.asarray(np.matmul(Rz,np.matmul(Ry,np.matmul(Rx, np.transpose(bcc_mat))))))\n",
    "    division_value = np.mean(transformed_bcc_mat[:,1] * correction_val)  \n",
    "\n",
    "    # perform reference frame transformations on raw data using Euler angles\n",
    "    # head\n",
    "    head_mat = np.matrix(df[headers[18:21]])\n",
    "    transformed_head_mat = np.transpose(np.asarray(np.matmul(Rz,np.matmul(Ry,np.matmul(Rx, np.transpose(head_mat))))))\n",
    "    head = transformed_head_mat * correction_val  \n",
    "\n",
    "    # thorax\n",
    "    thorax_mat = np.matrix(df[headers[24:27]])\n",
    "    transformed_thorax_mat = np.transpose(np.asarray(np.matmul(Rz,np.matmul(Ry,np.matmul(Rx, np.transpose(thorax_mat))))))\n",
    "    thorax = transformed_thorax_mat * correction_val\n",
    "\n",
    "    # abdomen\n",
    "    abdomen_mat = np.matrix(df[headers[30:33]])\n",
    "    transformed_abdomen_mat = np.transpose(np.asarray(np.matmul(Rz,np.matmul(Ry,np.matmul(Rx, np.transpose(abdomen_mat))))))\n",
    "    abdomen = transformed_abdomen_mat * correction_val\n",
    "\n",
    "    # R1 \n",
    "    r1_mat = np.matrix(df[headers[36:39]])\n",
    "    transformed_r1_mat = np.transpose(np.asarray(np.matmul(Rz,np.matmul(Ry,np.matmul(Rx, np.transpose(r1_mat))))))\n",
    "    r1_raw = transformed_r1_mat * correction_val\n",
    "    r1 = r1_raw - thorax # normalize these to the thorax (~center of mass)\n",
    "\n",
    "    # R2\n",
    "    r2_mat = np.matrix(df[headers[42:45]])\n",
    "    transformed_r2_mat = np.transpose(np.asarray(np.matmul(Rz,np.matmul(Ry,np.matmul(Rx, np.transpose(r2_mat))))))\n",
    "    r2_raw = transformed_r2_mat * correction_val\n",
    "    r2 = r2_raw - thorax\n",
    "\n",
    "    # R3\n",
    "    r3_mat = np.matrix(df[headers[48:51]])\n",
    "    transformed_r3_mat = np.transpose(np.asarray(np.matmul(Rz,np.matmul(Ry,np.matmul(Rx, np.transpose(r3_mat))))))\n",
    "    r3_raw = transformed_r3_mat * correction_val\n",
    "    r3 = r3_raw - thorax\n",
    "\n",
    "    # L1\n",
    "    l1_mat = np.matrix(df[headers[54:57]])\n",
    "    transformed_l1_mat = np.transpose(np.asarray(np.matmul(Rz,np.matmul(Ry,np.matmul(Rx, np.transpose(l1_mat))))))\n",
    "    l1_raw = transformed_l1_mat * correction_val\n",
    "    l1 = l1_raw - thorax # normalize these to the thorax (~center of mass)\n",
    "\n",
    "    # L2\n",
    "    l2_mat = np.matrix(df[headers[60:63]])\n",
    "    transformed_l2_mat = np.transpose(np.asarray(np.matmul(Rz,np.matmul(Ry,np.matmul(Rx, np.transpose(l2_mat))))))\n",
    "    l2_raw = transformed_l2_mat * correction_val\n",
    "    l2 = l2_raw - thorax\n",
    "\n",
    "    # L3\n",
    "    l3_mat = np.matrix(df[headers[66:69]])\n",
    "    transformed_l3_mat = np.transpose(np.asarray(np.matmul(Rz,np.matmul(Ry,np.matmul(Rx, np.transpose(l3_mat))))))\n",
    "    l3_raw = transformed_l3_mat * correction_val\n",
    "    l3 = l3_raw - thorax\n",
    "    \n",
    "    # collect y positions of tarsi in chamber coordinates\n",
    "    tarsi_pos_chamber = [r1_raw, r2_raw, r3_raw, l1_raw, l2_raw, l3_raw]\n",
    "\n",
    "    # seperate legs into there own dimensions\n",
    "    # isolate the x position only of the legs\n",
    "    r1_x=r1[:,0]\n",
    "    r2_x=r2[:,0]\n",
    "    r3_x=r3[:,0]\n",
    "    l1_x=l1[:,0]\n",
    "    l2_x=l2[:,0]\n",
    "    l3_x=l3[:,0]\n",
    "\n",
    "    x_pos_raw=[r1_x, r2_x, r3_x, l1_x, l2_x, l3_x]\n",
    "\n",
    "    # isolate the y position only of the legs\n",
    "    r1_y=r1[:,1]\n",
    "    r2_y=r2[:,1]\n",
    "    r3_y=r3[:,1]\n",
    "    l1_y=l1[:,1]\n",
    "    l2_y=l2[:,1]\n",
    "    l3_y=l3[:,1]\n",
    "\n",
    "    y_pos_raw=[r1_y, r2_y, r3_y, l1_y, l2_y, l3_y]\n",
    "\n",
    "    # isolate the x position only of the legs\n",
    "    r1_z=r1[:,2]\n",
    "    r2_z=r2[:,2]\n",
    "    r3_z=r3[:,2]\n",
    "    l1_z=l1[:,2]\n",
    "    l2_z=l2[:,2]\n",
    "    l3_z=l3[:,2]\n",
    "\n",
    "    z_pos=[r1_z, r2_z, r3_z, l1_z, l2_z, l3_z]\n",
    "    \n",
    "    # only look are raw position\n",
    "    r1_x_raw =r1_raw[:,0]\n",
    "    r2_x_raw =r2_raw[:,0]\n",
    "    r3_x_raw =r3_raw[:,0]\n",
    "    l1_x_raw =l1_raw[:,0]\n",
    "    l2_x_raw =l2_raw[:,0]\n",
    "    l3_x_raw =l3_raw[:,0]\n",
    "    x_pos_allocentric = [r1_x_raw, r2_x_raw, r3_x_raw, l1_x_raw, l2_x_raw, l3_x_raw]\n",
    "    \n",
    "    # only look are raw position\n",
    "    r1_y_raw =r1_raw[:,1]\n",
    "    r2_y_raw =r2_raw[:,1]\n",
    "    r3_y_raw =r3_raw[:,1]\n",
    "    l1_y_raw =l1_raw[:,1]\n",
    "    l2_y_raw =l2_raw[:,1]\n",
    "    l3_y_raw =l3_raw[:,1]\n",
    "    y_pos_allocentric = [r1_y_raw, r2_y_raw, r3_y_raw, l1_y_raw, l2_y_raw, l3_y_raw]\n",
    "    \n",
    "    # only look are raw position\n",
    "    r1_z_raw =r1_raw[:,2]\n",
    "    r2_z_raw =r2_raw[:,2]\n",
    "    r3_z_raw =r3_raw[:,2]\n",
    "    l1_z_raw =l1_raw[:,2]\n",
    "    l2_z_raw =l2_raw[:,2]\n",
    "    l3_z_raw =l3_raw[:,2]\n",
    "    z_pos_raw = [r1_z_raw, r2_z_raw, r3_z_raw, l1_z_raw, l2_z_raw, l3_z_raw]\n",
    "    \n",
    "    # convert head, thorax, and abdomen arrays into dataframes\n",
    "    head = pd.DataFrame(head, columns=headers[18:21])\n",
    "    thorax = pd.DataFrame(thorax, columns=headers[24:27]) \n",
    "    abdomen = pd.DataFrame(abdomen, columns=headers[30:33])\n",
    "\n",
    "    # transform the data so that the fly is superimposed on itself\n",
    "#     x_pos = x_pos_raw\n",
    "#     y_pos = y_pos_raw\n",
    "    \n",
    "    [x_pos, y_pos]=coordinate_transform(x_pos_raw, y_pos_raw, thorax, head, abdomen)\n",
    "\n",
    "    return head, thorax, abdomen, x_pos, y_pos, z_pos, z_pos_raw, tarsi_pos_chamber, division_value, x_pos_allocentric, y_pos_allocentric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align fly to a common heading angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_transform(x_pos, y_pos, thorax, head, abdomen):\n",
    "\n",
    "    # extract data and adjust for the mirroring in y\n",
    "    r1_x = x_pos[0]\n",
    "    r1_y = -y_pos[0] \n",
    "\n",
    "    r2_x = x_pos[1]\n",
    "    r2_y = -y_pos[1] \n",
    "\n",
    "    r3_x = x_pos[2]\n",
    "    r3_y = -y_pos[2] \n",
    "\n",
    "    l1_x = x_pos[3]\n",
    "    l1_y = -y_pos[3] \n",
    "\n",
    "    l2_x = x_pos[4]\n",
    "    l2_y = -y_pos[4] \n",
    "\n",
    "    l3_x = x_pos[5]\n",
    "    l3_y = -y_pos[5] \n",
    "\n",
    "    # body position\n",
    "    tx=thorax['thorax_x'] \n",
    "    ty=thorax['thorax_y'] \n",
    "\n",
    "    hx=np.array(head['head_x'] - tx.values.astype(float))\n",
    "    hy=-(np.array(head['head_y'] - ty.values.astype(float)))\n",
    "\n",
    "    ax=abdomen['abdomen_x'] - tx.values.astype(float)\n",
    "    ay=-(abdomen['abdomen_y'] - ty.values.astype(float))\n",
    "\n",
    "    # store variables\n",
    "    n_frames=len(hx)\n",
    "    new_hx=np.zeros(n_frames)\n",
    "    new_hy=np.zeros(n_frames)\n",
    "    new_ax=np.zeros(n_frames)\n",
    "    new_ay=np.zeros(n_frames)\n",
    "    new_r1_x=np.zeros(n_frames)\n",
    "    new_r1_y=np.zeros(n_frames)\n",
    "    new_r2_x=np.zeros(n_frames)\n",
    "    new_r2_y=np.zeros(n_frames)\n",
    "    new_r3_x=np.zeros(n_frames)\n",
    "    new_r3_y=np.zeros(n_frames)\n",
    "    new_l1_x=np.zeros(n_frames)\n",
    "    new_l1_y=np.zeros(n_frames)\n",
    "    new_l2_x=np.zeros(n_frames)\n",
    "    new_l2_y=np.zeros(n_frames)\n",
    "    new_l3_x=np.zeros(n_frames)\n",
    "    new_l3_y=np.zeros(n_frames)\n",
    "\n",
    "\n",
    "    for j in range(n_frames):\n",
    "\n",
    "        # compute heading angle\n",
    "        if hx[j]<0:\n",
    "            sign=-1\n",
    "            mirror_x=-1 # mirror across x\n",
    "            mirror_y=-1 # mirror across y\n",
    "\n",
    "        else:\n",
    "            sign=1\n",
    "            mirror_x=1\n",
    "            mirror_y=1\n",
    "        l_head=sign*math.sqrt(hx[j]**2 + hy[j]**2) # distance the head is away from the thorax\n",
    "        heading_angle=math.asin(hy[j]/l_head) # headin angle in radians\n",
    "        # new head positions\n",
    "        new_hx[j]=mirror_x*l_head\n",
    "        new_hy[j]=0 # heading angle should become zero\n",
    "\n",
    "        # new abdomen position\n",
    "        if ax[j]<0:\n",
    "            sign=-1\n",
    "        else:\n",
    "            sign=1\n",
    "        l_abdo=sign*math.sqrt(ax[j]**2 + ay[j]**2)\n",
    "        abdo_angle=math.asin(ay[j]/l_abdo)\n",
    "        new_abdo_angle=abdo_angle - heading_angle # compute angle of r1 adjusted by the heading angle\n",
    "        new_ax[j]=mirror_x*l_abdo*math.cos(new_abdo_angle)\n",
    "        new_ay[j]=mirror_y*l_abdo*math.sin(new_abdo_angle)\n",
    "\n",
    "        # compute the new 2D position of each leg\n",
    "        # r1\n",
    "        if r1_x[j]<0:\n",
    "            sign=-1\n",
    "        else:\n",
    "            sign=1\n",
    "        l_r1=sign*math.sqrt(r1_x[j]**2 + r1_y[j]**2)\n",
    "        r1_angle=math.asin(r1_y[j]/l_r1)\n",
    "        new_r1_angle=r1_angle - heading_angle # compute angle of r1 adjusted by the heading angle\n",
    "        new_r1_x[j]=mirror_x*l_r1*math.cos(new_r1_angle)\n",
    "        new_r1_y[j]=mirror_y*l_r1*math.sin(new_r1_angle)\n",
    "\n",
    "        # r2\n",
    "        if r2_x[j]<0:\n",
    "            sign=-1\n",
    "        else:\n",
    "            sign=1\n",
    "        l_r2=sign*math.sqrt(r2_x[j]**2 + r2_y[j]**2)\n",
    "        r2_angle=math.asin(r2_y[j]/l_r2)\n",
    "        new_r2_angle=r2_angle - heading_angle # compute angle of r1 adjusted by the heading angle\n",
    "        new_r2_x[j]=mirror_x*l_r2*math.cos(new_r2_angle)\n",
    "        new_r2_y[j]=mirror_y*l_r2*math.sin(new_r2_angle)\n",
    "\n",
    "        # r3\n",
    "        if r3_x[j]<0:\n",
    "            sign=-1\n",
    "        else:\n",
    "            sign=1\n",
    "        l_r3=sign*math.sqrt(r3_x[j]**2 + r3_y[j]**2)\n",
    "        r3_angle=math.asin(r3_y[j]/l_r3)\n",
    "        new_r3_angle=r3_angle - heading_angle # compute angle of r1 adjusted by the heading angle\n",
    "        new_r3_x[j]=mirror_x*l_r3*math.cos(new_r3_angle)\n",
    "        new_r3_y[j]=mirror_y*l_r3*math.sin(new_r3_angle)\n",
    "\n",
    "        # l1\n",
    "        if l1_x[j]<0:\n",
    "            sign=-1\n",
    "        else:\n",
    "            sign=1\n",
    "        l_l1=sign*math.sqrt(l1_x[j]**2 + l1_y[j]**2)\n",
    "        l1_angle=math.asin(l1_y[j]/l_l1)\n",
    "        new_l1_angle=l1_angle - heading_angle # compute angle of r1 adjusted by the heading angle\n",
    "        new_l1_x[j]=mirror_x*l_l1*math.cos(new_l1_angle)\n",
    "        new_l1_y[j]=mirror_y*l_l1*math.sin(new_l1_angle)\n",
    "\n",
    "        # l2\n",
    "        if l2_x[j]<0:\n",
    "            sign=-1\n",
    "        else:\n",
    "            sign=1\n",
    "        l_l2=sign*math.sqrt(l2_x[j]**2 + l2_y[j]**2)\n",
    "        l2_angle=math.asin(l2_y[j]/l_l2)\n",
    "        new_l2_angle=l2_angle - heading_angle # compute angle of r1 adjusted by the heading angle\n",
    "        new_l2_x[j]=mirror_x*l_l2*math.cos(new_l2_angle)\n",
    "        new_l2_y[j]=mirror_y*l_l2*math.sin(new_l2_angle)\n",
    "\n",
    "        # l3\n",
    "        if l3_x[j]<0:\n",
    "            sign=-1\n",
    "        else:\n",
    "            sign=1\n",
    "        l_l3=sign*math.sqrt(l3_x[j]**2 + l3_y[j]**2)\n",
    "        l3_angle=math.asin(l3_y[j]/l_l3)\n",
    "        new_l3_angle=l3_angle - heading_angle # compute angle of r1 adjusted by the heading angle\n",
    "        new_l3_x[j]=mirror_x*l_l3*math.cos(new_l3_angle)\n",
    "        new_l3_y[j]=mirror_y*l_l3*math.sin(new_l3_angle)\n",
    "\n",
    "    # store leg arrays\n",
    "    x_pos=[new_r1_x, new_r2_x, new_r3_x, new_l1_x, new_l2_x, new_l3_x]\n",
    "    y_pos=[-new_r1_y, -new_r2_y, -new_r3_y, -new_l1_y, -new_l2_y, -new_l3_y]\n",
    "\n",
    "    # store rotated body arrays\n",
    "    rot_head=[new_hx, new_hy]\n",
    "    rot_abdomen=[new_ax, new_ay]\n",
    "\n",
    "    return x_pos, y_pos\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the velocity of the fly\n",
    "\n",
    "Ground truth velocity of the belts in the tied condition is between 7-7.5 mm/s. This was confirmed using the movement of the belt teeth as seen by the top down camera in Fiji. \n",
    "\n",
    "Compute the flies walking speed w.r.t to the driving speed direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vel(head, thorax, trial_speed):\n",
    "    \n",
    "    # velocity parameters \n",
    "    dt = 1/FS\n",
    "    tx=thorax['thorax_x'] \n",
    "    ty=thorax['thorax_y'] \n",
    "    tz=thorax['thorax_z']\n",
    "    dx=np.diff(tx)\n",
    "    dy=np.diff(ty)\n",
    "    dz=np.diff(tz)\n",
    "    \n",
    "    # calculate total velocity\n",
    "    M = np.sqrt(dx**2 + dy**2 + dz**2)\n",
    "    sign=np.ones(len(dx))\n",
    "    sign[np.where(dx<0)[0]]=-1\n",
    "    vel = (sign*M)/dt + trial_speed\n",
    "    \n",
    "    # filter the velocity with a 1D Gaussian filter with sigma of 2\n",
    "    sigma = 2\n",
    "    filt_vel = gaussian_filter1d(vel, sigma)\n",
    "    lin_vel = filt_vel\n",
    "    \n",
    "    # calculate the fly's walking speed parallel to the driving speed axis\n",
    "    vel_parallel = vel = dx/dt + trial_speed\n",
    "    filt_vel_parallel = gaussian_filter1d(vel_parallel, sigma)\n",
    "    \n",
    "    # calculate the fly's walking speed perpendicular to the driving speed axis\n",
    "    vel_perpendicular = abs(dy)/dt \n",
    "    filt_vel_perpendicular = gaussian_filter1d(vel_perpendicular, sigma)\n",
    "              \n",
    "    # compute heading angle\n",
    "    # body position\n",
    "    hx=np.array(head['head_x'] - tx.values.astype(float))\n",
    "    hy=-(np.array(head['head_y'] - ty.values.astype(float)))\n",
    "   \n",
    "    heading_angle=np.zeros(len(hx))\n",
    "    for j in range(len(hx)):\n",
    "        # compute heading angle\n",
    "        if hx[j]<0:\n",
    "            \n",
    "            # adjust for 180 degrees\n",
    "            sign=-1\n",
    "            l_head=sign*math.sqrt(hx[j]**2 + hy[j]**2) # distance the head is away from the thorax\n",
    "            angle=math.asin(hy[j]/l_head) # headin angle in radians\n",
    "            if angle<0:\n",
    "                heading_angle[j]=math.degrees((math.pi + angle))\n",
    "            else:\n",
    "                heading_angle[j]=math.degrees((angle - math.pi))\n",
    "            \n",
    "        else:\n",
    "            sign=1\n",
    "            l_head=sign*math.sqrt(hx[j]**2 + hy[j]**2) # distance the head is away from the thorax\n",
    "            heading_angle[j]=math.degrees(math.asin(hy[j]/l_head)) # headin angle in radians\n",
    "            \n",
    "    return lin_vel, filt_vel_parallel, filt_vel_perpendicular, heading_angle\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Body Length\n",
    "\n",
    "Normalize spatial kinematic parameters by body length so that comparasions between flies can be conducted.\n",
    "\n",
    "Normalize by dividing spatial parameter by body length [mm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_BL(head, abdomen):\n",
    "\n",
    "    # head coordinates\n",
    "    hx = head['head_x']\n",
    "    hy = head['head_y']\n",
    "    hz = head['head_z']\n",
    "\n",
    "    # abdomen coordinates\n",
    "    ax = abdomen['abdomen_x']\n",
    "    ay = abdomen['abdomen_y']\n",
    "    az = abdomen['abdomen_z']\n",
    "\n",
    "    # compute the difference\n",
    "    dx = hx - ax\n",
    "    dy = hy - ay\n",
    "    dz = hz - az\n",
    "\n",
    "    # Calculate the body lengths for the trial\n",
    "    BL = np.sqrt(dx**2 + dy**2 + dz**2)\n",
    "\n",
    "    # filter the body length for when the fly is walking\n",
    "    #filtered_BL = BL[walking_indices]\n",
    "\n",
    "    # calculate the median BL\n",
    "    median_BL = np.median(BL)\n",
    "    \n",
    "    return median_BL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute step amplitude or stride length \n",
    "stride length: AEP to subsequent AEP (PROBLEM: walking in place results in no change in this parameter)\n",
    "\n",
    "step amplitude: total distance between PEP and AEP (focus on this)\n",
    "\n",
    "swing distance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_swing_distance(stance_start, stance_end, x_pos, y_pos, z_pos_raw, BL):\n",
    "    swing_distance =  np.empty((nlegs, trial_samples))\n",
    "    swing_distance[:] = np.nan\n",
    "    for leg in range(len(stance_start)):\n",
    "        for j in range(len(stance_start[leg])-1):\n",
    "            # compute step length\n",
    "            dx = x_pos[leg][stance_end[leg][j]:stance_start[leg][j+1]] \n",
    "            dy = y_pos[leg][stance_end[leg][j]:stance_start[leg][j+1]]\n",
    "            dz = z_pos_raw[leg][stance_end[leg][j]:stance_start[leg][j+1]] \n",
    "            amplitude=np.sum(np.sqrt(np.diff(dx)**2 + np.diff(dy)**2 + np.diff(dz)**2))/BL \n",
    "\n",
    "            # filter out zero distance because it is attibuted to a tracking error\n",
    "            if amplitude > 0:\n",
    "                swing_distance[leg,stance_start[leg][j]] = amplitude # normalize by body length\n",
    "\n",
    "    return swing_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stance_distance(stance_start, stance_end, x_pos, y_pos, z_pos_raw, BL):\n",
    "    stance_distance =  np.empty((nlegs, trial_samples))\n",
    "    stance_distance[:] = np.nan\n",
    "    for leg in range(len(stance_start)):\n",
    "        for j in range(len(stance_start[leg])):\n",
    "            # compute step length\n",
    "            dx = x_pos[leg][stance_start[leg][j]:stance_end[leg][j]]\n",
    "            dy = y_pos[leg][stance_start[leg][j]:stance_end[leg][j]]\n",
    "            dz = z_pos_raw[leg][stance_start[leg][j]:stance_end[leg][j]] \n",
    "            amplitude=np.sum(np.sqrt(np.diff(dx)**2 + np.diff(dy)**2 + np.diff(dz)**2))/BL\n",
    "\n",
    "            # filter out zero distance because it is attibuted to a tracking error\n",
    "            if amplitude > 0:\n",
    "                stance_distance[leg,stance_start[leg][j]] = amplitude # normalize by body length\n",
    "            \n",
    "    return stance_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_step_distance(x_pos, y_pos, z_pos_raw, stance_start, stance_end, BL, FS):\n",
    "    step_distance =  np.empty((nlegs, trial_samples))\n",
    "    step_distance[:] = np.nan\n",
    "    \n",
    "    # compute stance and swing speed and sum both from step speed\n",
    "    for leg in range(len(stance_start)):\n",
    "        # calculate the stance and swing speed for each step\n",
    "        for j in range(len(stance_start[leg])-1):\n",
    "\n",
    "            # compute distance traveled during the step\n",
    "            # stance distance\n",
    "            st_dx = x_pos[leg][stance_start[leg][j]:stance_end[leg][j]] \n",
    "            st_dy = y_pos[leg][stance_start[leg][j]:stance_end[leg][j]]\n",
    "            st_dz = z_pos_raw[leg][stance_start[leg][j]:stance_end[leg][j]]\n",
    "            st_distance = np.sum(np.sqrt(np.diff(st_dx)**2 + np.diff(st_dy)**2))/BL\n",
    "\n",
    "            # swing distance\n",
    "            sw_dx = x_pos[leg][stance_end[leg][j]:stance_start[leg][j+1]] \n",
    "            sw_dy = y_pos[leg][stance_end[leg][j]:stance_start[leg][j+1]]\n",
    "            sw_dz = z_pos_raw[leg][stance_end[leg][j]:stance_start[leg][j+1]] \n",
    "            sw_distance = np.sum(np.sqrt(np.diff(sw_dx)**2 + np.diff(sw_dy)**2))/BL\n",
    "\n",
    "            # step distance\n",
    "            step_dist = st_distance + sw_distance\n",
    "            \n",
    "            if (st_distance > 0) and (sw_distance > 0):\n",
    "                step_distance[leg, stance_start[leg][j]] = step_dist\n",
    "                \n",
    "    return step_distance \n",
    "                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swing and Stance Duration, and Duty Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swing_stance_duration(stance_start, stance_end):\n",
    "    stance_duration =  np.empty((nlegs, trial_samples))\n",
    "    stance_duration[:] = np.nan\n",
    "\n",
    "    swing_duration =  np.empty((nlegs, trial_samples))\n",
    "    swing_duration[:] = np.nan\n",
    "\n",
    "    duty_factor =  np.empty((nlegs, trial_samples))\n",
    "    duty_factor[:] = np.nan\n",
    "\n",
    "    for leg in range(len(stance_start)):\n",
    "        for j in range(len(stance_start[leg])-1):\n",
    "            stance_delt=(stance_end[leg][j]-stance_start[leg][j])/FS\n",
    "            if stance_delt > 0:\n",
    "                stance_duration[leg, stance_start[leg][j]] = stance_delt\n",
    "\n",
    "            swing_delt=(stance_start[leg][j+1] - stance_end[leg][j])/FS\n",
    "            if swing_delt > 0:\n",
    "                swing_duration[leg, stance_start[leg][j]] = swing_delt\n",
    "\n",
    "            # compute the duty factor\n",
    "            if (swing_delt > 0) and (stance_delt > 0):\n",
    "                df=stance_delt/(stance_delt + swing_delt)\n",
    "                duty_factor[leg, stance_start[leg][j]] = df\n",
    "    \n",
    "    return stance_duration, swing_duration, duty_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Frequency\n",
    "step frequency: 1/ change in time between stance starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_step_freq(stance_start):\n",
    "    step_frequency =  np.empty((nlegs, trial_samples))\n",
    "    step_frequency[:] = np.nan\n",
    "    for leg in range(len(stance_start)):\n",
    "        for j in range(len(stance_start[leg])-1):\n",
    "            step_duration=(stance_start[leg][j+1] - stance_start[leg][j])/FS\n",
    "            if step_duration>0:\n",
    "                step_frequency[leg, stance_start[leg][j]] = 1/step_duration\n",
    "    \n",
    "    return step_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swing Height\n",
    "\n",
    "Calculate the height of swing for each leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute swing height\n",
    "def compute_swing_height(x_pos, y_pos, z_pos_raw, stance_start, stance_end, BL):\n",
    "    swing_height =  np.empty((nlegs, trial_samples))\n",
    "    swing_height[:] = np.nan\n",
    "    buffer_frames = 3\n",
    "    for leg in range(len(stance_start)):\n",
    "        for j in range(len(stance_start[leg])-1):\n",
    "\n",
    "            # determine the max height of the step\n",
    "            curr_swing = z_pos_raw[leg][stance_end[leg][j] - buffer_frames : stance_start[leg][j+1] + buffer_frames] /BL\n",
    "            max_z = max(curr_swing)\n",
    "\n",
    "            # determine the median z value during the preceeding stance\n",
    "            mean_stance_z = np.mean(z_pos_raw[leg][stance_start[leg][j]:stance_end[leg][j]] /BL)\n",
    "\n",
    "            # height of swing\n",
    "            curr_h = abs(max_z- mean_stance_z)\n",
    "            if curr_h > 0:\n",
    "                swing_height[leg, stance_start[leg][j]] = curr_h\n",
    "\n",
    "    return swing_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swing Linearity\n",
    "\n",
    "Measure how how variable the lateral movement of the leg during swing is relative to following the shortest path possible from PEP to AEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_swing_linearity(x_pos, y_pos, stance_start, stance_end, BL):\n",
    "    swing_linearity =  np.empty((nlegs, trial_samples))\n",
    "    swing_linearity[:] = np.nan\n",
    "    N = 100 # number of samples for interpolation (swing phase)\n",
    "\n",
    "    for leg in range(len(stance_start)):\n",
    "        for j in range(len(stance_start[leg])-1):\n",
    "\n",
    "            # current swing trajectory along x and y (body and lateral axes)\n",
    "            curr_swing_x = x_pos[leg][stance_end[leg][j]:stance_start[leg][j+1]] /BL\n",
    "            curr_swing_y = y_pos[leg][stance_end[leg][j]:stance_start[leg][j+1]] /BL\n",
    "\n",
    "            # interpolate\n",
    "            if len(curr_swing_x) > 2:\n",
    "                fx = interpolate.interp1d(curr_swing_x , curr_swing_y)\n",
    "                interp_x = np.linspace(curr_swing_x[0], curr_swing_x[-1], N)\n",
    "                ynew = fx(interp_x)\n",
    "                ynew_adj = ynew - ynew[0]\n",
    "\n",
    "\n",
    "                # create the straight (shortest path)\n",
    "                straight_traj = np.linspace(ynew_adj[0], ynew_adj[-1], N)\n",
    "                error = np.sum(abs(ynew_adj - straight_traj)) # absolute error from path\n",
    "\n",
    "            else:\n",
    "                error = np.nan\n",
    "\n",
    "            # store absolute error \n",
    "            swing_linearity[leg, stance_start[leg][j]] = error\n",
    "            \n",
    "    return swing_linearity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step, stance, and swing speeds\n",
    "\n",
    "$$speed = \\frac{distance}{duration} [BL/s] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tarsi_speeds(x_pos, y_pos, z_pos_raw, stance_start, stance_end, BL, FS):\n",
    "    step_speed =  np.empty((nlegs, trial_samples))\n",
    "    step_speed[:] = np.nan\n",
    "    \n",
    "    stance_speed =  np.empty((nlegs, trial_samples))\n",
    "    stance_speed[:] = np.nan\n",
    "    \n",
    "    swing_speed =  np.empty((nlegs, trial_samples))\n",
    "    swing_speed[:] = np.nan\n",
    "\n",
    "    # compute stance and swing speed and sum both from step speed\n",
    "    for leg in range(len(stance_start)):\n",
    "        # calculate the stance and swing speed for each step\n",
    "        for j in range(len(stance_start[leg])-1):\n",
    "            # determine stance and swing duration\n",
    "            st_d = (stance_end[leg][j] - stance_start[leg][j])/FS # stance duration\n",
    "            sw_d = (stance_start[leg][j+1] - stance_end[leg][j])/FS\n",
    "            step_d = st_d + sw_d\n",
    "\n",
    "            # compute distance traveled during the step\n",
    "            # stance distance\n",
    "            st_dx = x_pos[leg][stance_start[leg][j]:stance_end[leg][j]] \n",
    "            st_dy = y_pos[leg][stance_start[leg][j]:stance_end[leg][j]]\n",
    "            st_dz = z_pos_raw[leg][stance_start[leg][j]:stance_end[leg][j]]\n",
    "            st_distance = np.sum(np.sqrt(np.diff(st_dx)**2 + np.diff(st_dy)**2 + np.diff(st_dz)**2))/BL\n",
    "\n",
    "            # swing distance\n",
    "            sw_dx = x_pos[leg][stance_end[leg][j]:stance_start[leg][j+1]] \n",
    "            sw_dy = y_pos[leg][stance_end[leg][j]:stance_start[leg][j+1]]\n",
    "            sw_dz = z_pos_raw[leg][stance_end[leg][j]:stance_start[leg][j+1]] \n",
    "            sw_distance = np.sum(np.sqrt(np.diff(sw_dx)**2 + np.diff(sw_dy)**2 + np.diff(sw_dz)**2))/BL\n",
    "\n",
    "            # step distance\n",
    "            step_distance = st_distance + sw_distance\n",
    "            \n",
    "            if (st_d > 0) and (sw_d > 0):\n",
    "                step_speed[leg, stance_start[leg][j]] = step_distance/step_d\n",
    "                stance_speed[leg, stance_start[leg][j]] = st_distance/st_d\n",
    "                swing_speed[leg, stance_start[leg][j]] = sw_distance/sw_d\n",
    "\n",
    "    return step_speed, stance_speed, swing_speed  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AEP and PEP\n",
    "AEP: Anterior extreme position, stance start...use stance time\n",
    "\n",
    "PEP: Posterior extreme position, stance end...use swing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the AEP and PEP \n",
    "def compute_AEP_PEP(x_pos, y_pos, stance_start, stance_end, BL):\n",
    "    AEPx =  np.empty((nlegs, trial_samples))\n",
    "    AEPx[:] = np.nan\n",
    "    AEPy =  np.empty((nlegs, trial_samples))\n",
    "    AEPy[:] = np.nan\n",
    "    PEPx =  np.empty((nlegs, trial_samples))\n",
    "    PEPx[:] = np.nan\n",
    "    PEPy =  np.empty((nlegs, trial_samples))\n",
    "    PEPy[:] = np.nan\n",
    "    \n",
    "    for leg in range(len(stance_start)):\n",
    "        for j in range(len(stance_start[leg])- 1):\n",
    "            # determine x and y position of AEP at the onset of stance normalized by body length\n",
    "            AEPx[leg, stance_start[leg][j]] = x_pos[leg][stance_start[leg][j]]/BL\n",
    "            AEPy[leg, stance_start[leg][j]] = y_pos[leg][stance_start[leg][j]]/BL\n",
    "\n",
    "            # determine x and y position of PEP at swing start/ end of stance phase normalized by body length\n",
    "            PEPx[leg, stance_start[leg][j]] = x_pos[leg][stance_end[leg][j]]/BL\n",
    "            PEPy[leg, stance_start[leg][j]] = y_pos[leg][stance_end[leg][j]]/BL\n",
    "\n",
    "    return AEPx, AEPy, PEPx, PEPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordination Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fractional coordination - delay in stance onset between legs using a reference leg\n",
    "\n",
    "1) L1 - R1 [3,0]\n",
    "\n",
    "2) L1 - R2 [3,1]\n",
    "\n",
    "3) L1 - R3 [3,2]\n",
    "\n",
    "4) L1 - L2 [3,4]\n",
    "\n",
    "5) L1 - L3 [3,5]\n",
    "\n",
    "6) L2 - R1 [4,0]\n",
    "\n",
    "7) L2 - R2 [4,1]\n",
    "\n",
    "8) L2 - R3 [4,2]\n",
    "\n",
    "9) L2 - L3 [4,5]\n",
    "\n",
    "10) L3 - R1 [5,0]\n",
    "\n",
    "11) L3 - R2 [5,1]\n",
    "\n",
    "12) L3 - R3 [5,2]\n",
    "\n",
    "13) R1 - R2 [0,1]\n",
    "\n",
    "14) R2 - R3 [1,2]\n",
    "\n",
    "15) R1 - L1 [0,3]\n",
    "\n",
    "16) R2 - L2 [1,4]\n",
    "\n",
    "17) R3 - L3 [2,5]\n",
    "\n",
    "#### Relative distance between legs at the AEP (stance start) of reference leg\n",
    "\n",
    "Distance = sqrt(X^2 + Y^2 + Z^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the phase relationship between legs\n",
    "def relative_phase_distance(stance_start, x_pos, y_pos, z_pos_raw, trial_samples):\n",
    "    leg_comparasions = [[3,0], [3,1], [3,2], [3,4], [3,5], [4,0], [4,1], [4,2], [4,5], [5,0], [5,1], [5,2], [0,1], [1,2],\n",
    "                       [0,3], [1,4], [2,5]]\n",
    "    step_phase = -np.ones((len(leg_comparasions), trial_samples))\n",
    "    relative_distance = -np.ones((len(leg_comparasions), trial_samples))\n",
    "    for j in range(len(leg_comparasions)):\n",
    "        leg1 = leg_comparasions[j][0]\n",
    "        leg2 = leg_comparasions[j][1]\n",
    "\n",
    "        for i in range(len(stance_start[leg1])-1):\n",
    "            stance_index = stance_start[leg2][np.logical_and(stance_start[leg2] >= stance_start[leg1][i], stance_start[leg2] < stance_start[leg1][i+1])]\n",
    "\n",
    "            if len(stance_index) > 0: # make sure there is a match - only consider the first index\n",
    "                step_phase[j, stance_start[leg1][i]] = (stance_index[0] - stance_start[leg1][i])/(stance_start[leg1][i+1]-stance_start[leg1][i])\n",
    "\n",
    "                # relative distance\n",
    "                dx = x_pos[leg1] - x_pos[leg2]\n",
    "                dy = y_pos[leg1] - y_pos[leg2]\n",
    "                dz = z_pos_raw[leg1] - z_pos_raw[leg2]\n",
    "                relative_distance[j, stance_start[leg1][i]] = np.sqrt(dx[stance_start[leg1][i]]**2 + dy[stance_start[leg1][i]]**2 + dz[stance_start[leg1][i]]**2)      \n",
    "    \n",
    "    return step_phase, relative_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instanteous phase difference between legs\n",
    "\n",
    "Note that the Hilbert transform works poorly on limb tip positions because the osccilatory nature of them is non-stationary (i.e. there is no one axis that captures the full osccilatory charactistics of leg movement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stance starts of legs relative to L1\n",
    "\n",
    "This is also a interlimb phase metric that compliments the method of using a hilbert transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_relative_stance_onset(stance_start, FS, walking_indices, trial_speed):\n",
    "    filt_ref_stance_onset = np.intersect1d(stance_start[3], walking_indices) # reference leg is L1, filtered stance onset\n",
    "    stance_onset_threshold = 0.15 # 150 ms... slowest step duration\n",
    "    leg_relative_stance_onset =  np.empty((5, trial_samples))\n",
    "    leg_relative_stance_onset[:] = np.nan\n",
    "    leg_cnt = -1\n",
    "    for leg in [0, 1, 2, 4, 5]:\n",
    "        leg_cnt += 1\n",
    "        for stance_frame in filt_ref_stance_onset:\n",
    "            curr_stance_onset = np.intersect1d(stance_start[leg], walking_indices)\n",
    "            if len(curr_stance_onset) > 0:\n",
    "                df_stance_onset = curr_stance_onset - stance_frame\n",
    "                min_idx = np.argmin(np.abs(df_stance_onset))\n",
    "                dt = (df_stance_onset[min_idx])/FS\n",
    "                if dt < stance_onset_threshold:\n",
    "                    leg_relative_stance_onset[leg_cnt, stance_frame] = dt\n",
    "        \n",
    "    return leg_relative_stance_onset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration of the number of legs in stance during walking bouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legs_in_stance_duration(nlegs_stance, trial_samples):\n",
    "    # duration of the number of legs in stance\n",
    "    duration_nlegs = np.zeros((6, trial_samples))\n",
    "    for j in np.arange(1,7).tolist():\n",
    "        nleg_idxs = np.where(nlegs_stance == j)[0]\n",
    "        if len(nleg_idxs>0):\n",
    "            # iterate through each\n",
    "            frame_start = nleg_idxs[0]\n",
    "            frame_counter = 0\n",
    "            for i in range(len(nleg_idxs)-1):\n",
    "                frame_counter += 1\n",
    "                if ((nleg_idxs[i+1] - nleg_idxs[i]) != 1) and (frame_counter > 1):\n",
    "                    frame_end = nleg_idxs[i]\n",
    "                    duration_nlegs[j-1, frame_start] = ((frame_end - frame_start)+1)/FS\n",
    "                    frame_start = nleg_idxs[i+1]\n",
    "                    frame_counter=0\n",
    "                elif ((nleg_idxs[i+1] - nleg_idxs[i]) != 1) and (frame_counter == 1): # configuration is just present for 1 frame\n",
    "                    duration_nlegs[j-1, frame_start] = 1/FS\n",
    "                    frame_start = nleg_idxs[i+1]\n",
    "                    frame_counter=0\n",
    "                elif (i == len(nleg_idxs)-2) and (frame_counter > 1): # right edge case\n",
    "                    frame_end = nleg_idxs[i+1]\n",
    "                    duration_nlegs[j-1, frame_start] = ((frame_end - frame_start)+1)/FS\n",
    "                elif (i == len(nleg_idxs)-2) and (frame_counter == 1):\n",
    "                    duration_nlegs[j-1, frame_start] = 1/FS\n",
    "    return duration_nlegs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tripod Coordination Strength\n",
    "\n",
    "TCS = t2/t1\n",
    "\n",
    "t2 = time that legs overlap during swing\n",
    "\n",
    "t1 =  abs(earliest swing onset - latest swing onset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tripod_coordination_strength(walking_indices, FS, stance_start, stance_end):\n",
    "\n",
    "    # find bounds of walking periods\n",
    "    walking_idx_diff = np.diff(walking_indices)\n",
    "    walking_bounds = np.where(walking_idx_diff>1)[0]\n",
    "    walking_periods = []\n",
    "    start_idx = walking_indices[0]\n",
    "    for j in range(len(walking_bounds)):\n",
    "\n",
    "        # boundary effect\n",
    "        if (len(walking_bounds) == j+1) and (walking_bounds[j] != len(walking_idx_diff)):\n",
    "            walking_periods.append([start_idx, walking_indices[walking_bounds[j]]])\n",
    "            start_idx = walking_indices[walking_bounds[j] + 1] \n",
    "            walking_periods.append([start_idx, walking_indices[-1]])\n",
    "        else: # for iterating through more than 2 walking periods\n",
    "            walking_periods.append([start_idx, walking_indices[walking_bounds[j]]])\n",
    "            start_idx = walking_indices[walking_bounds[j] + 1] \n",
    "\n",
    "    # find swing phases within these walking periods\n",
    "    right_tcs = np.zeros(trial_samples)\n",
    "    left_tcs = np.zeros(trial_samples)\n",
    "    for walking_bout in range(len(walking_periods)):\n",
    "        # start and end of walking bouts\n",
    "        start_bout = walking_periods[walking_bout][0]\n",
    "        end_bout = walking_periods[walking_bout][1]\n",
    "\n",
    "        # right tripod\n",
    "        # r1\n",
    "        r1_swing_onsets = stance_end[0][np.where(np.logical_and(stance_end[0]>= start_bout, stance_end[0]<= end_bout))[0]]\n",
    "        try:\n",
    "            r1_swing_end = stance_start[0][np.where(np.logical_and(stance_end[0]>= start_bout, stance_end[0]<= end_bout))[0] + 1]\n",
    "        except:\n",
    "            break\n",
    "\n",
    "        # l2\n",
    "        l2_swing_onsets = stance_end[4][np.where(np.logical_and(stance_end[4]>= start_bout, stance_end[4]<= end_bout))[0]]\n",
    "        try:\n",
    "            l2_swing_end = stance_start[4][np.where(np.logical_and(stance_end[4]>= start_bout, stance_end[4]<= end_bout))[0] + 1]\n",
    "        except:\n",
    "            break\n",
    "\n",
    "        # r3\n",
    "        r3_swing_onsets = stance_end[2][np.where(np.logical_and(stance_end[2]>= start_bout, stance_end[2]<= end_bout))[0]]\n",
    "        try:\n",
    "            r3_swing_end = stance_start[2][np.where(np.logical_and(stance_end[2]>= start_bout, stance_end[2]<= end_bout))[0] + 1]\n",
    "        except:\n",
    "            break\n",
    "\n",
    "        # if sizes of these arrays are not the same then reformat them\n",
    "        if (len(r1_swing_onsets) != len(l2_swing_onsets)) or (len(r1_swing_onsets) != len(r3_swing_onsets)):\n",
    "            # use the array that is the smallest in size\n",
    "            cat_arrays = [r1_swing_onsets, l2_swing_onsets, r3_swing_onsets]\n",
    "            cat_arrays_end = [r1_swing_end, l2_swing_end, r3_swing_end]\n",
    "            min_size_array = np.argmin(np.array([len(r1_swing_onsets), len(l2_swing_onsets), len(r3_swing_onsets)]))\n",
    "            other_array_idxs = np.setdiff1d(np.arange(0,len(cat_arrays)), np.array([min_size_array]))\n",
    "\n",
    "            for k in range(len(other_array_idxs)):\n",
    "                if len(cat_arrays[min_size_array]) != len(cat_arrays[other_array_idxs[k]]):\n",
    "\n",
    "                    # find matches\n",
    "                    other_array_matches_onset = np.zeros(len(cat_arrays[min_size_array]))\n",
    "                    other_array_matches_end = np.zeros(len(cat_arrays[min_size_array]))\n",
    "                    for onset in range(len(cat_arrays[min_size_array])):\n",
    "                        match_idx = np.argmin(abs(cat_arrays[other_array_idxs[k]] - cat_arrays[min_size_array][onset]))\n",
    "                        other_array_matches_onset[onset] = cat_arrays[other_array_idxs[k]][match_idx]\n",
    "                        other_array_matches_end[onset] = cat_arrays_end[other_array_idxs[k]][match_idx]\n",
    "\n",
    "                    # replace prior array with new array\n",
    "                    if other_array_idxs[k] == 0:\n",
    "                        r1_swing_onsets = other_array_matches_onset\n",
    "                        r1_swing_end = other_array_matches_end\n",
    "                    elif other_array_idxs[k] == 1:\n",
    "                        l2_swing_onsets = other_array_matches_onset\n",
    "                        l2_swing_end = other_array_matches_end\n",
    "                    else:\n",
    "                        r3_swing_onsets = other_array_matches_onset\n",
    "                        r3_swing_end = other_array_matches_end\n",
    "\n",
    "        for i in range(len(r1_swing_onsets)):\n",
    "            # enforce that swing termination doesn't exceed the walking bout bounds\n",
    "            if (r1_swing_end[i] <= end_bout) and (l2_swing_end[i] <= end_bout) and (r3_swing_end[i] <= end_bout):\n",
    "                # make sure that for the given swing that there is overlap for the legs within the tripod\n",
    "                r1_swing_frames= np.arange(r1_swing_onsets[i], r1_swing_end[i]+1)\n",
    "                l2_swing_frames= np.arange(l2_swing_onsets[i], l2_swing_end[i]+1)\n",
    "                r3_swing_frames= np.arange(r3_swing_onsets[i], r3_swing_end[i]+1)\n",
    "\n",
    "                # see if they intersect\n",
    "                if (len(np.intersect1d(r1_swing_frames, l2_swing_frames))>0) and (len(np.intersect1d(r1_swing_frames, r3_swing_frames))>0) and (len(np.intersect1d(l2_swing_frames, r3_swing_frames))>0):\n",
    "                    # if all of the legs within a tripod share frames, then compute tcs\n",
    "                    curr_swing_onset = np.array([r1_swing_onsets[i], l2_swing_onsets[i], r3_swing_onsets[i]])\n",
    "                    curr_swing_end = np.array([r1_swing_end[i], l2_swing_end[i], r3_swing_end[i]])\n",
    "\n",
    "                    # compute the total duration of the tripod\n",
    "                    t1 = (max(curr_swing_end) - min(curr_swing_onset))/FS\n",
    "\n",
    "                    # compute the time that all legs are in swing together\n",
    "                    overlap_r1_l2 = np.intersect1d(r1_swing_frames, l2_swing_frames)\n",
    "                    overlap_all_legs = np.intersect1d(overlap_r1_l2, r3_swing_frames)\n",
    "                    t2 = (overlap_all_legs[-1] - overlap_all_legs[0])/FS\n",
    "                    right_tcs[int(overlap_all_legs[0])] = t2/t1\n",
    "\n",
    "\n",
    "        # left tripod\n",
    "        # l1\n",
    "        l1_swing_onsets = stance_end[3][np.where(np.logical_and(stance_end[3]>= start_bout, stance_end[3]<= end_bout))[0]]\n",
    "        try:\n",
    "            l1_swing_end = stance_start[3][np.where(np.logical_and(stance_end[3]>= start_bout, stance_end[3]<= end_bout))[0] + 1]\n",
    "        except:\n",
    "            break\n",
    "\n",
    "        # r2\n",
    "        r2_swing_onsets = stance_end[1][np.where(np.logical_and(stance_end[1]>= start_bout, stance_end[1]<= end_bout))[0]]\n",
    "        try:\n",
    "            r2_swing_end = stance_start[1][np.where(np.logical_and(stance_end[1]>= start_bout, stance_end[1]<= end_bout))[0] + 1]\n",
    "        except:\n",
    "            break\n",
    "\n",
    "        # l3\n",
    "        l3_swing_onsets = stance_end[5][np.where(np.logical_and(stance_end[5]>= start_bout, stance_end[5]<= end_bout))[0]]\n",
    "        try:\n",
    "            l3_swing_end = stance_start[5][np.where(np.logical_and(stance_end[5]>= start_bout, stance_end[5]<= end_bout))[0] + 1]\n",
    "        except:\n",
    "            break\n",
    "\n",
    "        # if sizes of these arrays are not the same then reformat them\n",
    "        if (len(l1_swing_onsets) != len(r2_swing_onsets)) or (len(l1_swing_onsets) != len(l3_swing_onsets)):\n",
    "            # use the array that is the smallest in size\n",
    "            cat_arrays = [l1_swing_onsets, r2_swing_onsets, l3_swing_onsets]\n",
    "            cat_arrays_end = [l1_swing_end, r2_swing_end, l3_swing_end]\n",
    "            min_size_array = np.argmin(np.array([len(l1_swing_onsets), len(r2_swing_onsets), len(l3_swing_onsets)]))\n",
    "            other_array_idxs = np.setdiff1d(np.arange(0,len(cat_arrays)), np.array([min_size_array]))\n",
    "\n",
    "            for k in range(len(other_array_idxs)):\n",
    "                if len(cat_arrays[min_size_array]) != len(cat_arrays[other_array_idxs[k]]):\n",
    "\n",
    "                    # find matches\n",
    "                    other_array_matches_onset = np.zeros(len(cat_arrays[min_size_array]))\n",
    "                    other_array_matches_end = np.zeros(len(cat_arrays[min_size_array]))\n",
    "                    for onset in range(len(cat_arrays[min_size_array])):\n",
    "                        match_idx = np.argmin(abs(cat_arrays[other_array_idxs[k]] - cat_arrays[min_size_array][onset]))\n",
    "                        other_array_matches_onset[onset] = cat_arrays[other_array_idxs[k]][match_idx]\n",
    "                        other_array_matches_end[onset] = cat_arrays_end[other_array_idxs[k]][match_idx]\n",
    "\n",
    "                    # replace prior array with new array\n",
    "                    if other_array_idxs[k] == 0:\n",
    "                        l1_swing_onsets = other_array_matches_onset\n",
    "                        l1_swing_end = other_array_matches_end\n",
    "                    elif other_array_idxs[k] == 1:\n",
    "                        r2_swing_onsets = other_array_matches_onset\n",
    "                        r2_swing_end = other_array_matches_end\n",
    "                    else:\n",
    "                        l3_swing_onsets = other_array_matches_onset\n",
    "                        l3_swing_end = other_array_matches_end\n",
    "\n",
    "        for i in range(len(r2_swing_onsets)):\n",
    "            # enforce that swing termination doesn't exceed the walking bout bounds\n",
    "            if (l1_swing_end[i] <= end_bout) and (r2_swing_end[i] <= end_bout) and (l3_swing_end[i] <= end_bout):\n",
    "                # make sure that for the given swing that there is overlap for the legs within the tripod\n",
    "                l1_swing_frames= np.arange(l1_swing_onsets[i], l1_swing_end[i]+1)\n",
    "                r2_swing_frames= np.arange(r2_swing_onsets[i], r2_swing_end[i]+1)\n",
    "                l3_swing_frames= np.arange(l3_swing_onsets[i], l3_swing_end[i]+1)\n",
    "\n",
    "                # see if they intersect\n",
    "                if (len(np.intersect1d(l1_swing_frames, r2_swing_frames))>0) and (len(np.intersect1d(l1_swing_frames, l3_swing_frames))>0) and (len(np.intersect1d(r2_swing_frames, l3_swing_frames))>0):\n",
    "                    # if all of the legs within a tripod share frames, then compute tcs\n",
    "                    curr_swing_onset = np.array([l1_swing_onsets[i], r2_swing_onsets[i], l3_swing_onsets[i]])\n",
    "                    curr_swing_end = np.array([l1_swing_end[i], r2_swing_end[i], l3_swing_end[i]])\n",
    "\n",
    "                    # compute the total duration of the tripod\n",
    "                    t1 = (max(curr_swing_end) - min(curr_swing_onset))/FS\n",
    "\n",
    "                    # compute the time that all legs are in swing together\n",
    "                    overlap_l1_r2 = np.intersect1d(l1_swing_frames, r2_swing_frames)\n",
    "                    overlap_all_legs = np.intersect1d(overlap_l1_r2, l3_swing_frames)\n",
    "                    t2 = (overlap_all_legs[-1] - overlap_all_legs[0])/FS\n",
    "                    left_tcs[int(overlap_all_legs[0])] = t2/t1\n",
    "                    \n",
    "    return right_tcs, left_tcs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posture Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate body height\n",
    "\n",
    "body height will be determined as the median stance height, which is normalized to thorax height. Thorax height can't be used because it needs to be relative to the distance the fly is from the belt... i.e. leg in stance to thorax height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comupte_body_height(swing_stance_mat, z_pos, BL):\n",
    "    bh = np.zeros(swing_stance_mat.shape[1])\n",
    "    for j in range(len(bh)):\n",
    "\n",
    "        # find the legs in stance - middle legs only\n",
    "        stance_boolean = swing_stance_mat[[1,4], j] == 1\n",
    "\n",
    "        # legs are in stance\n",
    "        if np.any(stance_boolean):\n",
    "            z_pos_midlegs = np.concatenate((np.array([z_pos[1][j]]), np.array([z_pos[4][j]])))\n",
    "            curr_bh = np.mean(z_pos_midlegs[stance_boolean])\n",
    "\n",
    "        else:\n",
    "            curr_bh = np.nan\n",
    "\n",
    "        # append median height to body height array\n",
    "        bh[j] = curr_bh/BL\n",
    "\n",
    "    # linear interpolation over the NANs\n",
    "    non_nan_frames = all_frames[~np.isnan(bh)]\n",
    "    non_nan_bh = bh[~np.isnan(bh)]\n",
    "    f = interpolate.interp1d(non_nan_frames, non_nan_bh, fill_value = 'extrapolate')\n",
    "    interp_bh = f(all_frames)\n",
    "\n",
    "    # smooth body height via a Gaussian Kernel\n",
    "    bh_filt = gaussian_filter1d(interp_bh, 10)\n",
    "        \n",
    "    return bh_filt       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Body Pitch\n",
    "\n",
    "Angle between head and thorax\n",
    "\n",
    " = arccos[(xa * xb + ya * yb + za * zb) / ((xa + ya + za) * (xb + yb + zb))]\n",
    "\n",
    "Pitch down (head is below the thorax) is negative\n",
    "\n",
    "Pitch up (head above the thorax) is positive\n",
    "\n",
    "####  head-thorax yaw angle - need 2 tracked positions on the head to calculate this parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_body_pitch(head, thorax):\n",
    "    # body positions \n",
    "    hx = head['head_x'].values\n",
    "    hy = head['head_y'].values\n",
    "    hz = head['head_z'].values\n",
    "    tx = thorax['thorax_x'].values\n",
    "    ty = thorax['thorax_y'].values\n",
    "    tz = thorax['thorax_z'].values\n",
    "\n",
    "    # normalize head coordinated relative to that of the thorax (reference frame)\n",
    "    norm_hx = hx - tx\n",
    "    norm_hy = hy - ty\n",
    "    norm_hz = hz - tz\n",
    "\n",
    "    # define vector coordinates\n",
    "    body_pitch = np.zeros(len(hx))\n",
    "\n",
    "    for j in range(len(hx)):\n",
    "        vec1 = np.array([norm_hx[j], norm_hy[j], norm_hz[j]]) # head vector\n",
    "        vec2 = np.array([norm_hx[j], norm_hy[j], 0]) # reference vector\n",
    "\n",
    "        # compute the angle\n",
    "        body_pitch[j] = np.arccos((vec1[0]*vec2[0] + vec1[1]*vec2[1] + vec1[2]*vec2[2])/(np.sqrt(np.sum(vec1**2))*np.sqrt(np.sum(vec2**2)))) * (180 / np.pi)\n",
    "\n",
    "    # add sign of angle such that pitch down is negative\n",
    "    body_pitch[norm_hz < 0] = -body_pitch[norm_hz < 0]\n",
    "    \n",
    "    return body_pitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Body angle\n",
    "\n",
    "Angle formed by the head, thorax, and abdomen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_body_angle(head, thorax, abdomen):\n",
    "    # body positions \n",
    "    hx = head['head_x'].values\n",
    "    hy = head['head_y'].values\n",
    "    hz = head['head_z'].values\n",
    "    tx = thorax['thorax_x'].values\n",
    "    ty = thorax['thorax_y'].values\n",
    "    tz = thorax['thorax_z'].values\n",
    "    ax = abdomen['abdomen_x'].values\n",
    "    ay = abdomen['abdomen_y'].values\n",
    "    az = abdomen['abdomen_z'].values\n",
    "\n",
    "    # lengths of each side of the triangle formed by the body\n",
    "    a = np.sqrt((tx-ax)**2 + (tz-az)**2 + (ty-ay)**2)\n",
    "    b = np.sqrt((tx-hx)**2 + (tz-hz)**2 + (ty-hy)**2)\n",
    "    c = np.sqrt((ax-hx)**2 + (az-hz)**2 + (ay-hy)**2)\n",
    "\n",
    "    # use the law od cosines to compute the body angle\n",
    "    body_angle = np.arccos((a**2 + b**2 - c**2)/(2*a*b)) * (180 / np.pi)\n",
    "    \n",
    "    return body_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Static stability and support polygon area\n",
    "\n",
    "Support polygon area corresponds to the spread of the legs\n",
    "\n",
    "Polgon area is calulated using the shoelace method - https://en.wikipedia.org/wiki/Shoelace_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute static stability for each frame\n",
    "def compute_static_stability(swing_stance_mat, x_pos, y_pos):\n",
    "    # plt_frame = 1528\n",
    "    N_samples = 100 # number of interpulated samples \n",
    "    static_stability = np.zeros(swing_stance_mat.shape[1])\n",
    "    polygon_area = np.zeros(swing_stance_mat.shape[1])\n",
    "\n",
    "    for curr_frame in range(swing_stance_mat.shape[1]): # [plt_frame]: \n",
    "        # find the legs in stance\n",
    "        swing_stance_frame = swing_stance_mat[:,curr_frame]\n",
    "        curr_legs_stance = np.where(swing_stance_frame == 1)[0].tolist()\n",
    "\n",
    "        # boundry condition for instances where there are no legs in stance\n",
    "        if len(curr_legs_stance) > 2: # need atleast 3 legs in stance to compute this metric\n",
    "\n",
    "            # get x (body) and y (lateral) coordinates\n",
    "            # reorder coordinates so that edges of the polygon are created in a piecewise fashion - only need to swtich L1 and L3\n",
    "            xy_coordinates = np.zeros((6, 2)) # make the full matrix and remove zeros after the fact\n",
    "            for j in curr_legs_stance:\n",
    "                if j == 3:\n",
    "                    xy_coordinates[5,0] = x_pos[j][curr_frame]\n",
    "                    xy_coordinates[5,1] = y_pos[j][curr_frame]\n",
    "                elif j == 5:\n",
    "                    xy_coordinates[3,0] = x_pos[j][curr_frame]\n",
    "                    xy_coordinates[3,1] = y_pos[j][curr_frame]\n",
    "                else:\n",
    "                    xy_coordinates[j,0] = x_pos[j][curr_frame]\n",
    "                    xy_coordinates[j,1] = y_pos[j][curr_frame]\n",
    "\n",
    "            # remove zeros (non-stance legs)\n",
    "            try: \n",
    "                xy_coordinates = xy_coordinates[xy_coordinates[:,0] != 0, :]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # replicate the first element in order to induce wrap around\n",
    "            xy_coordinates = np.vstack((xy_coordinates, xy_coordinates[0,:]))\n",
    "\n",
    "            # determine if the COM lies inside or outside of the polygon\n",
    "            '''\n",
    "            Ray tracing method: if horizontal line from COM intersects odd number of lines - inside of polygon, else outside\n",
    "            '''\n",
    "           # find the line that defines each edge\n",
    "            y_coords = xy_coordinates[:,1]\n",
    "            x_coords = xy_coordinates[:,0]\n",
    "            edges = 0\n",
    "            for e in range(len(y_coords)-1):\n",
    "                m = (y_coords[e+1] - y_coords[e])/(x_coords[e+1] - x_coords[e])\n",
    "                b = y_coords[e] - (m*x_coords[e])\n",
    "\n",
    "                # determine the x that corresponds to y = 0 # COM\n",
    "                x_intercept = -b/m\n",
    "                curr_xvals = np.array([x_coords[e+1], x_coords[e]])\n",
    "\n",
    "                # Ray tracing is to the right, so only looking at x intercept values greater than 0\n",
    "                if (x_intercept > 0) and (x_intercept >= np.min(curr_xvals)) and (x_intercept <= np.max(curr_xvals)):\n",
    "                    edges+=1\n",
    "\n",
    "            # if edges is even, including zeros, the COM is outside of the COM, otherwise it is inside\n",
    "            edges_clause = np.mod(edges,2)\n",
    "            if edges_clause == 0:\n",
    "                static_stability[curr_frame] = 0 # COM outside of polygon\n",
    "            else:\n",
    "                # continue with claculating static stability\n",
    "                # linear interpolation between each coordination and find minimum distance\n",
    "                min_distances = np.zeros(xy_coordinates.shape[0] -1)\n",
    "                min_coordinates = np.zeros((xy_coordinates.shape[0] -1,2))\n",
    "                for i in range(xy_coordinates.shape[0] -1):\n",
    "                    x = np.array([xy_coordinates[i, 0], xy_coordinates[i+1, 0]])\n",
    "                    y = np.array([xy_coordinates[i, 1], xy_coordinates[i+1, 1]])\n",
    "                    f_line = interpolate.interp1d(x, y)\n",
    "                    x_expand = np.linspace(x[0], x[1], N_samples)\n",
    "                    y_expand = f_line(x_expand)\n",
    "\n",
    "                    # now find the minimum distance of this line\n",
    "                    distance = np.sqrt(x_expand**2 + y_expand**2)\n",
    "                    min_distance = np.min(distance)\n",
    "                    min_distances[i] = min_distance\n",
    "                    min_idx = np.argmin(distance)\n",
    "                    min_coordinate = np.array([x_expand[min_idx], y_expand[min_idx]])\n",
    "                    min_coordinates[i,:] = min_coordinate\n",
    "\n",
    "                static_stability[curr_frame] = np.min(min_distances)\n",
    "                polygon_area[curr_frame] = 0.5*np.abs(np.dot(xy_coordinates[0:-1,0],np.roll(xy_coordinates[0:-1,1],1))-np.dot(xy_coordinates[:,1],np.roll(xy_coordinates[:,0],1)))\n",
    "                \n",
    "    return static_stability, polygon_area \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limb velocity based swing stance classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swing_stance_classification(x_pos_allocentric, y_pos_allocentric, FS, nlegs, trial_samples):\n",
    "\n",
    "    dt = 1/FS\n",
    "    r1_vel = np.sqrt(np.diff(x_pos_allocentric[0])**2 + np.diff(y_pos_allocentric[0])**2)/dt\n",
    "    r2_vel = np.sqrt(np.diff(x_pos_allocentric[1])**2 + np.diff(y_pos_allocentric[1])**2)/dt\n",
    "    r3_vel = np.sqrt(np.diff(x_pos_allocentric[2])**2 + np.diff(y_pos_allocentric[2])**2)/dt\n",
    "    l1_vel = np.sqrt(np.diff(x_pos_allocentric[3])**2 + np.diff(y_pos_allocentric[3])**2)/dt\n",
    "    l2_vel = np.sqrt(np.diff(x_pos_allocentric[4])**2 + np.diff(y_pos_allocentric[4])**2)/dt\n",
    "    l3_vel = np.sqrt(np.diff(x_pos_allocentric[5])**2 + np.diff(y_pos_allocentric[5])**2)/dt\n",
    "\n",
    "    # add sign\n",
    "    r1_vel[np.diff(x_pos_allocentric[0])<0] = -1*r1_vel[np.diff(x_pos_allocentric[0])<0]\n",
    "    r2_vel[np.diff(x_pos_allocentric[1])<0] = -1*r2_vel[np.diff(x_pos_allocentric[1])<0]\n",
    "    r3_vel[np.diff(x_pos_allocentric[2])<0] = -1*r3_vel[np.diff(x_pos_allocentric[2])<0]\n",
    "    l1_vel[np.diff(x_pos_allocentric[3])<0] = -1*l1_vel[np.diff(x_pos_allocentric[3])<0]\n",
    "    l2_vel[np.diff(x_pos_allocentric[4])<0] = -1*l2_vel[np.diff(x_pos_allocentric[4])<0]\n",
    "    l3_vel[np.diff(x_pos_allocentric[5])<0] = -1*l3_vel[np.diff(x_pos_allocentric[5])<0]\n",
    "\n",
    "    # smooth velocities using a gaussian filter\n",
    "    s =1 # sigma parameter\n",
    "    r1_smoothed_vel = gaussian_filter1d(r1_vel, s)\n",
    "    r2_smoothed_vel = gaussian_filter1d(r2_vel, s)\n",
    "    r3_smoothed_vel = gaussian_filter1d(r3_vel, s)\n",
    "    l1_smoothed_vel = gaussian_filter1d(l1_vel, s)\n",
    "    l2_smoothed_vel = gaussian_filter1d(l2_vel, s)\n",
    "    l3_smoothed_vel = gaussian_filter1d(l3_vel, s)\n",
    "\n",
    "    # swing stance classification - forward steps\n",
    "    swing_stance_mat=np.zeros([nlegs, trial_samples])\n",
    "    velocity_threshold = 5 # velocities above 5 mm/s are classified as swing\n",
    "    swing_stance_mat[0, np.concatenate((np.array([[r1_smoothed_vel < velocity_threshold][0][0]]), r1_smoothed_vel < velocity_threshold))] = 1\n",
    "    swing_stance_mat[1, np.concatenate((np.array([[r2_smoothed_vel < velocity_threshold][0][0]]), r2_smoothed_vel < velocity_threshold))] = 1\n",
    "    swing_stance_mat[2, np.concatenate((np.array([[r3_smoothed_vel < velocity_threshold][0][0]]), r3_smoothed_vel < velocity_threshold))] = 1\n",
    "    swing_stance_mat[3, np.concatenate((np.array([[l1_smoothed_vel < velocity_threshold][0][0]]), l1_smoothed_vel < velocity_threshold))] = 1\n",
    "    swing_stance_mat[4, np.concatenate((np.array([[l2_smoothed_vel < velocity_threshold][0][0]]), l2_smoothed_vel < velocity_threshold))] = 1\n",
    "    swing_stance_mat[5, np.concatenate((np.array([[l3_smoothed_vel < velocity_threshold][0][0]]), l3_smoothed_vel < velocity_threshold))] = 1\n",
    "\n",
    "    # swing stance classification - backward steps\n",
    "    velocity_threshold = -25 # velocities below 25 mm/s are also considered swing\n",
    "    swing_stance_mat[0, np.concatenate((np.array([[r1_smoothed_vel < velocity_threshold][0][0]]), r1_smoothed_vel < velocity_threshold))] = 0\n",
    "    swing_stance_mat[1, np.concatenate((np.array([[r2_smoothed_vel < velocity_threshold][0][0]]), r2_smoothed_vel < velocity_threshold))] = 0\n",
    "    swing_stance_mat[2, np.concatenate((np.array([[r3_smoothed_vel < velocity_threshold][0][0]]), r3_smoothed_vel < velocity_threshold))] = 0\n",
    "    swing_stance_mat[3, np.concatenate((np.array([[l1_smoothed_vel < velocity_threshold][0][0]]), l1_smoothed_vel < velocity_threshold))] = 0\n",
    "    swing_stance_mat[4, np.concatenate((np.array([[l2_smoothed_vel < velocity_threshold][0][0]]), l2_smoothed_vel < velocity_threshold))] = 0\n",
    "    swing_stance_mat[5, np.concatenate((np.array([[l3_smoothed_vel < velocity_threshold][0][0]]), l3_smoothed_vel < velocity_threshold))] = 0\n",
    "    \n",
    "    \n",
    "    # swing and stance transitions\n",
    "    stance_start = []\n",
    "    stance_end = []\n",
    "    for leg in range(nlegs):\n",
    "        swing_stance_diff = np.diff(swing_stance_mat[leg,:])\n",
    "        leg_stance_starts = all_frames[np.concatenate((np.array([False]),swing_stance_diff == 1))][1:-1] # ignore first and last stance onset - trial edge effects\n",
    "        leg_swing_starts = all_frames[np.concatenate((np.array([False]),swing_stance_diff == -1))][1:-1]\n",
    "\n",
    "        # find stance and swing onset matching pairs\n",
    "        leg_stance_end = []\n",
    "        for stance in range(len(leg_stance_starts)):\n",
    "            stance_idx = leg_stance_starts[stance]\n",
    "            try: # just in case there is an edge effect (end of trial)\n",
    "                leg_stance_end.append(leg_swing_starts[[leg_swing_starts - stance_idx][0] > 0][0])\n",
    "            except: # remove stance start index\n",
    "                leg_stance_starts = leg_stance_starts[leg_stance_starts != stance_idx] \n",
    "\n",
    "        # convert stance end into a numpy array\n",
    "        leg_stance_end = np.array(leg_stance_end)\n",
    "\n",
    "        # append stance start and end data across legs\n",
    "        stance_start.append(leg_stance_starts)\n",
    "        stance_end.append(leg_stance_end)\n",
    "        \n",
    "    return swing_stance_mat, stance_start, stance_end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter walking based on heading, velocity, orientation, and position within chamber\n",
    "\n",
    "Non-walking occurs when the velocity is less than zero...fly is pulled back by the belts\n",
    "\n",
    "In addition, non-walking only occurs for periods greater than 100 ms (a little less than a step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standing_filter(nlegs_stance, x_pos_allocentric, y_pos_allocentric, FS):\n",
    "    # standing filter\n",
    "    temp_standing_idxs = np.where(nlegs_stance==6)[0]\n",
    "\n",
    "    # filter standing indices to ensure tht no grooming is occuring based on tarsi tip velocity\n",
    "    dt = 1/FS\n",
    "    r1_vel = np.sqrt(np.diff(x_pos_allocentric[0])**2 + np.diff(y_pos_allocentric[0])**2)/dt\n",
    "    r2_vel = np.sqrt(np.diff(x_pos_allocentric[1])**2 + np.diff(y_pos_allocentric[1])**2)/dt\n",
    "    r3_vel = np.sqrt(np.diff(x_pos_allocentric[2])**2 + np.diff(y_pos_allocentric[2])**2)/dt\n",
    "    l1_vel = np.sqrt(np.diff(x_pos_allocentric[3])**2 + np.diff(y_pos_allocentric[3])**2)/dt\n",
    "    l2_vel = np.sqrt(np.diff(x_pos_allocentric[4])**2 + np.diff(y_pos_allocentric[4])**2)/dt\n",
    "    l3_vel = np.sqrt(np.diff(x_pos_allocentric[5])**2 + np.diff(y_pos_allocentric[5])**2)/dt\n",
    "\n",
    "    # add sign\n",
    "    r1_vel[np.diff(x_pos_allocentric[0])<0] = -1*r1_vel[np.diff(x_pos_allocentric[0])<0]\n",
    "    r2_vel[np.diff(x_pos_allocentric[1])<0] = -1*r2_vel[np.diff(x_pos_allocentric[1])<0]\n",
    "    r3_vel[np.diff(x_pos_allocentric[2])<0] = -1*r3_vel[np.diff(x_pos_allocentric[2])<0]\n",
    "    l1_vel[np.diff(x_pos_allocentric[3])<0] = -1*l1_vel[np.diff(x_pos_allocentric[3])<0]\n",
    "    l2_vel[np.diff(x_pos_allocentric[4])<0] = -1*l2_vel[np.diff(x_pos_allocentric[4])<0]\n",
    "    l3_vel[np.diff(x_pos_allocentric[5])<0] = -1*l3_vel[np.diff(x_pos_allocentric[5])<0]\n",
    "\n",
    "    # smooth velocities using a gaussian filter\n",
    "    s =1 # sigma parameter\n",
    "    r1_smoothed_vel = gaussian_filter1d(r1_vel, s)\n",
    "    r2_smoothed_vel = gaussian_filter1d(r2_vel, s)\n",
    "    r3_smoothed_vel = gaussian_filter1d(r3_vel, s)\n",
    "    l1_smoothed_vel = gaussian_filter1d(l1_vel, s)\n",
    "    l2_smoothed_vel = gaussian_filter1d(l2_vel, s)\n",
    "    l3_smoothed_vel = gaussian_filter1d(l3_vel, s)\n",
    "\n",
    "    standing_idxs = []\n",
    "    for i in range(len(temp_standing_idxs)):\n",
    "        curr_idx = temp_standing_idxs[i]\n",
    "        if curr_idx < 3999:\n",
    "            vel_check = np.array([r1_smoothed_vel[curr_idx]<0, r2_smoothed_vel[curr_idx]<0, r3_smoothed_vel[curr_idx]<0,\n",
    "                                 l1_smoothed_vel[curr_idx]<0, l2_smoothed_vel[curr_idx]<0, l3_smoothed_vel[curr_idx]<0])\n",
    "            if np.all(vel_check):\n",
    "                standing_idxs.append(curr_idx)\n",
    "\n",
    "    standing_idxs = np.array(standing_idxs)\n",
    "    standing_bouts =[]\n",
    "    counter = 0\n",
    "    for j in range(len(standing_idxs)-1):\n",
    "        if counter == 0:\n",
    "            bout_start = standing_idxs[j]\n",
    "\n",
    "        curr_diff = standing_idxs[j+1] - standing_idxs[j]\n",
    "        if curr_diff == 1:\n",
    "            counter +=1\n",
    "        elif counter > 0 and curr_diff != 1:\n",
    "            bout_end = standing_idxs[j]\n",
    "            standing_bouts.append([bout_start, bout_end, counter+1])\n",
    "            counter = 0\n",
    "        if counter > 0 and j==len(standing_idxs)-2 and curr_diff == 1:\n",
    "            bout_end = standing_idxs[j]\n",
    "            standing_bouts.append([bout_start, bout_end, counter+1])\n",
    "\n",
    "    standing_bouts = np.array(standing_bouts)  \n",
    "\n",
    "    # filter by standing bout duration\n",
    "    standing_threshold = 30 # frames - empirically chosen and corresponds to 150 ms worth of standing\n",
    "    try:\n",
    "        filt_standing_bouts = standing_bouts[standing_bouts[:,2] > standing_threshold,:]\n",
    "    except:\n",
    "        filt_standing_bouts = np.array([])\n",
    "\n",
    "    # combine frames of all standing bouts\n",
    "    standing_frames = np.array([])\n",
    "    for j in range(filt_standing_bouts.shape[0]):\n",
    "        if j ==0:\n",
    "            standing_frames = np.arange(filt_standing_bouts[j,0], filt_standing_bouts[j,1]+1)\n",
    "        else:\n",
    "            standing_frames = np.concatenate((standing_frames, np.arange(filt_standing_bouts[j,0], filt_standing_bouts[j,1]+1)))\n",
    "   \n",
    "    return standing_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heading_velocity_temporal_filter(heading_angle, filt_vel_parallel):\n",
    "\n",
    "    # use a forward velocity and heading angle classification window to classify forward walking\n",
    "    width = 40 # frames ... 200 ms > 2 steps - sets the walking bout duration\n",
    "    heading_upperlim = [15, 90, -15] # forward, right, and left turns\n",
    "    heading_lowerlim = [-15, 15, -90]\n",
    "    reverse_direction = np.flip(all_frames)\n",
    "    v_lower_lim = 5 # mm/s\n",
    "    vel_signal = np.concatenate((np.array([0]),filt_vel_parallel)) # concatenate a velocity of zero to front of vel array\n",
    "    walking_classification_indices = []\n",
    "    for bound in range(len(heading_upperlim)):\n",
    "        # filter in the forward direction\n",
    "        cnt = 0\n",
    "        for j in range(len(heading_angle) - width):\n",
    "            curr_vel = vel_signal[j:j+width]\n",
    "            curr_heading = heading_angle[j:j + width]\n",
    "\n",
    "            vel_classification = np.all(curr_vel > v_lower_lim)\n",
    "            heading_classification = np.all(np.logical_and(curr_heading < heading_upperlim[bound], curr_heading > heading_lowerlim[bound]))\n",
    "\n",
    "            # check to see if both classification criteria are true... if so, then this is a period of walking\n",
    "            if vel_classification and heading_classification:\n",
    "                if cnt ==0:\n",
    "                    forward_walking_idxs = np.arange(j, j+width) # classify as non-walking indices\n",
    "                    cnt = 1\n",
    "                else:\n",
    "                    forward_walking_idxs = np.unique(np.concatenate((forward_walking_idxs, np.arange(j, j+width))))\n",
    "\n",
    "        # filter in the backward direction\n",
    "        cnt = 0\n",
    "        for j in range(len(heading_angle) - width):\n",
    "            curr_vel = np.flip(vel_signal)[j:j+width]\n",
    "            curr_heading = np.flip(heading_angle)[j:j+width]\n",
    "\n",
    "            vel_classification = np.all(curr_vel > v_lower_lim)\n",
    "            heading_classification = np.all(np.logical_and(curr_heading < heading_upperlim[bound], curr_heading > heading_lowerlim[bound]))\n",
    "\n",
    "            # check to see if both classification criteria are true... if so, then this is a period of walking\n",
    "            if vel_classification and heading_classification:\n",
    "                if cnt ==0:\n",
    "                    backward_walking_idxs = reverse_direction[np.arange(j, j+width)] # classify as non-walking indices\n",
    "                    cnt = 1\n",
    "                else:\n",
    "                    backward_walking_idxs = np.unique(np.concatenate((backward_walking_idxs, reverse_direction[np.arange(j, j+width)])))\n",
    "\n",
    "\n",
    "\n",
    "        # find the intersection of the two arrays\n",
    "        try:\n",
    "            walking_idxs = np.intersect1d(forward_walking_idxs, backward_walking_idxs)\n",
    "            walking_classification_indices.append(walking_idxs)\n",
    "            del forward_walking_idxs\n",
    "            del backward_walking_idxs\n",
    "        except:\n",
    "            walking_classification_indices.append([])\n",
    "        \n",
    "    return walking_classification_indices[0], walking_classification_indices[1], walking_classification_indices[2] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior classifier \n",
    "\n",
    "#### Key:\n",
    "\n",
    "0- Other\n",
    "\n",
    "1- Forward walking bout\n",
    "\n",
    "2- Left turning bout\n",
    "\n",
    "3- Right turning bout\n",
    "\n",
    "4 - Standing\n",
    "\n",
    "5 - Tracking error\n",
    "\n",
    "6 - Front of Chamber\n",
    "\n",
    "7 - Back of Chamber\n",
    "\n",
    "8 - Upside Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal filter for heading angle and walking speed\n",
    "def Behavior_Classification(heading_angle, lin_vel, head, thorax, abdomen, all_frames, curr_tracked_data, trial_samples, nlegs_stance, trial, trial_offset_samples, x_pos_allocentric, y_pos_allocentric, FS):\n",
    "    \n",
    "    # classify movement periods\n",
    "    forward_indices, right_turn_indices, left_turn_indices = heading_velocity_temporal_filter(heading_angle, lin_vel)\n",
    "\n",
    "    # filter walking based on upright orientation... throax and abdomen\n",
    "    tz= thorax['thorax_z']\n",
    "    az= abdomen['abdomen_z']\n",
    "    ta_upside_down_indices = all_frames[az>tz]\n",
    "\n",
    "    # filter walking based on upright orientation... head and abdomen\n",
    "    hz=head['head_z']\n",
    "    az=abdomen['abdomen_z']\n",
    "    ha_upside_down_indices = all_frames[az>hz]\n",
    "\n",
    "    # find the intersection of the vertical orientation filters\n",
    "    upside_down_indices = np.unique(np.concatenate((ta_upside_down_indices, ha_upside_down_indices)))\n",
    "\n",
    "    # tracking error filters ~ large tracking errors are associated with the fly being upside down\n",
    "    error_threshold = 15 # check for split belt tracking - OK\n",
    "    leg_error = np.nanmean((curr_tracked_data[['r1_error', 'r2_error', 'r3_error', 'l1_error', 'l2_error', 'l3_error']].values), axis =1)\n",
    "    filter_leg_error = gaussian_filter1d(leg_error, 8) # filter leg error to remove instaneous errors \n",
    "    error_indices = np.where(filter_leg_error>error_threshold)[0]\n",
    "\n",
    "    # filters on the position of the fly \n",
    "    # back of chamber edge effect...hind legs are occulded\n",
    "    ax = abdomen['abdomen_x']\n",
    "    back_chamber_indices = np.where(ax <= 1.85)[0] # Changed (10/17/22) - more conservative threshold based on the mean of empirical data\n",
    "\n",
    "    # front of chamber edge of effect... front legs make contact with the front chamber wall\n",
    "    r1x = curr_tracked_data['r1_x'].values\n",
    "    l1x = curr_tracked_data['l1_x'].values\n",
    "    front_chamber_indices = all_frames[np.logical_or(r1x > 3.55, l1x > 3.55)] #Changed - conservative threshold\n",
    "\n",
    "    # frames that the fly is standing given the number of legs in stance\n",
    "    standing_frames = standing_filter(nlegs_stance, x_pos_allocentric, y_pos_allocentric, FS)\n",
    "\n",
    "    # reinforce upside down indices - need to remove those  \n",
    "    behavior_classifier = np.zeros(trial_samples)\n",
    "\n",
    "    # add keys for each behavioral label\n",
    "    # forward walking\n",
    "    try:\n",
    "        behavior_classifier[forward_indices] = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # left turns\n",
    "    try:\n",
    "        behavior_classifier[left_turn_indices] = 2\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # right turns\n",
    "    try:\n",
    "        behavior_classifier[right_turn_indices] = 3\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # standing\n",
    "    try:\n",
    "        behavior_classifier[standing_frames] = 4\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # tracking error\n",
    "    try:\n",
    "        behavior_classifier[error_indices] = 5\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # front of chamber\n",
    "    try:\n",
    "        behavior_classifier[front_chamber_indices] = 6\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # back of chamber\n",
    "    try:\n",
    "        behavior_classifier[back_chamber_indices] = 7\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # upside down\n",
    "    try:\n",
    "        behavior_classifier[upside_down_indices] = 8\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # add a mask if it is trial 1\n",
    "    if trial == 1:\n",
    "        behavior_classifier[0:trial_offset_samples] = 0 # just mask the behavior classifier here\n",
    "        \n",
    "    # filter out short walking sequences - convert to other category\n",
    "    # duration of the number of legs in stance\n",
    "\n",
    "    # iterate through forward walking, left turning, and right turning\n",
    "    frame_threshold = 50 # walking for 250 ms ~ 2- 4 steps\n",
    "    behs = [1, 2, 3] # forward, left, right\n",
    "    for repeat in range(5): # re run twice to remove any exception cases that result from the first round of filtering\n",
    "        for j in behs:\n",
    "            beh_idxs = np.where(behavior_classifier == j)[0]\n",
    "            if len(beh_idxs) > 0:\n",
    "                frame_start = beh_idxs[0]\n",
    "                frame_counter = 0\n",
    "                for i in range(len(beh_idxs)-1):\n",
    "                    frame_counter += 1\n",
    "                    if (beh_idxs[i+1] - beh_idxs[i]) != 1:\n",
    "                        frame_end = beh_idxs[i]\n",
    "                        if frame_counter == 1: #only one index\n",
    "                            behavior_classifier[frame_start]=0\n",
    "                        elif frame_counter < frame_threshold: # short behavior sequence\n",
    "                            behavior_classifier[frame_start:frame_end]=0 # convert short walking sequences to other category\n",
    "                        elif i == len(beh_idxs)-2: # filters out right edge case\n",
    "                            behavior_classifier[beh_idxs[i+1]]=0\n",
    "                        frame_start = beh_idxs[i+1]\n",
    "                        frame_counter=0\n",
    "                    elif (i == len(beh_idxs)-2) and (frame_counter < frame_threshold): # right edge case\n",
    "                        frame_end = beh_idxs[i+1]\n",
    "                        behavior_classifier[frame_start:frame_end]=0\n",
    "                        behavior_classifier[frame_end]=0\n",
    "\n",
    "    # just for forward walking trim the start and end of a walking bout\n",
    "    beh_idxs = np.where(behavior_classifier == 1)[0]\n",
    "    trim_frames = 20 # 18 trim edges of walking bout by 100 ms (removes kinematics resulting from transitions)\n",
    "\n",
    "    # isolate walking bouts\n",
    "    if len(beh_idxs) >0: # there is a walking bout\n",
    "        # find the number of walking bouts\n",
    "        if len(np.where(np.diff(beh_idxs) != 1)[0]) == 0:\n",
    "            behavior_classifier[beh_idxs[0]:beh_idxs[0]+trim_frames]=0 # trim the start of a walking bout\n",
    "#             behavior_classifier[beh_idxs[-1]-trim_frames:beh_idxs[-1]]=0 # trim the end of a walking bout\n",
    "        else:\n",
    "            start_idx = beh_idxs[0]\n",
    "            for j in range(len(beh_idxs)-1):\n",
    "                if (beh_idxs[j+1] - beh_idxs[j]) !=1:\n",
    "                    end_idx = beh_idxs[j]\n",
    "                    behavior_classifier[start_idx:start_idx+trim_frames+1]=0\n",
    "#                     behavior_classifier[end_idx-trim_frames:end_idx+1]=08\n",
    "                    start_idx = beh_idxs[j+1]\n",
    "    \n",
    "    # percent walking given the number of walking frames above\n",
    "    walking_indices = np.concatenate((np.where(behavior_classifier == 1)[0], np.where(behavior_classifier == 2)[0], np.where(behavior_classifier == 3)[0]))\n",
    "    percent_walking = len(walking_indices)/trial_samples\n",
    "    \n",
    "    return behavior_classifier, percent_walking, walking_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_behavior_classification(swing_stance_mat, behavior_classifier, fly, trial, save_plot):\n",
    "\n",
    "    # plot swing stance with behavioral classificaiton overlaid\n",
    "    color_code = ['gray', 'springgreen','salmon','teal', 'purple', 'red', 'yellow', 'blue', 'darkorange']\n",
    "    fig = plt.figure(1, figsize=[20,8])\n",
    "    title = 'Fly ' + str(fly)+ ' Trial '+ str(trial)+ ' Filtered Swing Stance Plot (stance = white; swing = black)'\n",
    "    plt.title(title, fontsize = 18)\n",
    "    plt.xlabel('frame number (#)', fontsize = 18)\n",
    "    plt.ylabel('leg', fontsize = 18)\n",
    "    labels = ['R1', 'R2', 'R3', 'L1', 'L2', 'L3']\n",
    "    axes = plt.gca()\n",
    "    axes.set_yticks(np.arange(0, 6, 1))\n",
    "    axes.set_yticklabels(labels)\n",
    "    plt.imshow(swing_stance_mat, interpolation = 'none', cmap = 'gray',aspect='auto')\n",
    "\n",
    "    # iterate through behavior classifier \n",
    "    iterator = 0\n",
    "    for j in range(len(behavior_classifier)-1):\n",
    "        if iterator == 0:\n",
    "            start_frame = j\n",
    "        beh_diff = behavior_classifier[j+1] - behavior_classifier[j]\n",
    "        if beh_diff == 0:\n",
    "            iterator = 1\n",
    "        else:\n",
    "    #         print('start frame = ', start_frame)\n",
    "    #         print('end frame = ', j)\n",
    "            plt.axvspan(start_frame, j, facecolor=color_code[int(behavior_classifier[j])], alpha=0.5)\n",
    "            iterator = 0\n",
    "\n",
    "    plt.axvspan(start_frame, j, facecolor=color_code[int(behavior_classifier[j])], alpha=0.5)\n",
    "    # Creating legend with color box\n",
    "    other_label = mpatches.Patch(color=color_code[0], label='Other')\n",
    "    other_forward = mpatches.Patch(color=color_code[1], label='Forward Walking')\n",
    "    other_left = mpatches.Patch(color=color_code[2], label='Left Turning')\n",
    "    other_right = mpatches.Patch(color=color_code[3], label='Right Turning')\n",
    "    other_standing = mpatches.Patch(color=color_code[4], label='Standing')\n",
    "    other_error = mpatches.Patch(color=color_code[5], label='Tracking Error')\n",
    "    other_front_chamber = mpatches.Patch(color=color_code[6], label='Front of Chamber')\n",
    "    other_back_chamber = mpatches.Patch(color=color_code[7], label='Back of Chamber')\n",
    "    other_upside = mpatches.Patch(color=color_code[8], label='Upside Down')\n",
    "\n",
    "    plt.legend(handles=[other_label, other_forward, other_left, other_right, other_standing, \n",
    "                       other_error, other_front_chamber, other_back_chamber, other_upside], fontsize = 14)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    if save_plot:\n",
    "        fig.savefig('Fly ' + str(fly)+ ' Trial '+ str(trial)+'_behavior_classifier_swing_stance.png', dpi = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_swing_stance(cnt, swing_stance_mat, non_walking_indices,fly, trial):\n",
    "    # plot swing stance\n",
    "    plt.figure(cnt + 1, figsize=[20,15])\n",
    "    plt.subplot(2,1,1)\n",
    "    title = 'Fly ' + str(fly)+ ' Trial '+ str(trial)+ ' Filtered Swing Stance Plot (stance = white; swing = black)'\n",
    "    plt.title(title, fontsize = 18)\n",
    "    plt.xlabel('frame number (#)', fontsize = 18)\n",
    "    plt.ylabel('leg', fontsize = 18)\n",
    "    labels = ['R1', 'R2', 'R3', 'L1', 'L2', 'L3']\n",
    "    axes = plt.gca()\n",
    "    axes.set_yticks(np.arange(0, 6, 1))\n",
    "    axes.set_yticklabels(labels)\n",
    "    plt.imshow(swing_stance_mat, interpolation = 'none', cmap = 'gray',aspect='auto')\n",
    "\n",
    "    # filter the swing stance mat\n",
    "    copy_swing_stance = swing_stance_mat.copy()\n",
    "    copy_swing_stance[:, non_walking_indices] = 0.5\n",
    "    plt.subplot(2,1,2)\n",
    "    title = 'Filtered Swing Stance Plot (stance = white; swing = black)'\n",
    "    plt.title(title, fontsize = 18)\n",
    "    plt.xlabel('frame number (#)', fontsize = 18)\n",
    "    plt.ylabel('leg', fontsize = 18)\n",
    "    labels = ['R1', 'R2', 'R3', 'L1', 'L2', 'L3']\n",
    "    axes = plt.gca()\n",
    "    axes.set_yticks(np.arange(0, 6, 1))\n",
    "    axes.set_yticklabels(labels)\n",
    "    plt.imshow(copy_swing_stance, interpolation = 'none', cmap = 'gray',aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify which belt each tarsi is associated with for each frame\n",
    "\n",
    "Classification arrays:\n",
    "\n",
    "-1: leg is present on left belt\n",
    "\n",
    "0: leg in between belt\n",
    "\n",
    "1: leg present on  right belt\n",
    "\n",
    "[r1, r2, r3, l1, l2, l3]\n",
    "\n",
    "#### KEY:\n",
    "\n",
    "True Split = [1, 1, 1, -1, -1, -1] - 0\n",
    "\n",
    "R1 false split = [-1 ,1 ,1, -1, -1, -1] - 1\n",
    "\n",
    "R2 false split = [1, -1, 1, -1, -1, -1] - 2\n",
    "\n",
    "R3 false split = [1, 1,-1,-1,-1,-1] - 3\n",
    "\n",
    "L1 false split = [1, 1, 1, 1, -1, -1] - 4\n",
    "\n",
    "L2 false split = [1, 1, 1, -1, 1, -1] - 5\n",
    "\n",
    "L3 false split = [1, 1, 1, -1, -1, 1] - 6\n",
    "\n",
    "False = any other combination - 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tarsi_belt_association(division_value, boundary_val, nlegs, tarsi_pos_chamber):\n",
    "    # Determine which belt the legs are associated with\n",
    "    LB_bound = division_value + boundary_val # left belt bound - accounts for a small gap\n",
    "    RB_bound = division_value - boundary_val # right belt bound - accounts for a small gap\n",
    "    tarsi_belt_classification = np.zeros(tarsi_pos_chamber[0].shape[0])\n",
    "    for frame in range(tarsi_pos_chamber[0].shape[0]):\n",
    "        classification_array = np.zeros(nlegs)\n",
    "        for leg in range(nlegs):\n",
    "            tarsi_y_pos = tarsi_pos_chamber[leg][frame,1]\n",
    "\n",
    "            # in between condition\n",
    "            if (tarsi_y_pos >= RB_bound) and (tarsi_y_pos <= LB_bound):\n",
    "                belt_class = 0\n",
    "            elif tarsi_y_pos > LB_bound:# leg present on left belt\n",
    "                belt_class = -1\n",
    "            else:\n",
    "                belt_class = 1\n",
    "\n",
    "            # construct classifciation array\n",
    "            classification_array[leg] = belt_class\n",
    "\n",
    "        # convert classification array into corresponding classification key\n",
    "        # true split\n",
    "        if np.all(classification_array == np.array([1, 1, 1, -1, -1, -1])):\n",
    "            class_key = 0 \n",
    "        elif np.all(classification_array == np.array([-1, 1, 1, -1, -1, -1])):\n",
    "            class_key = 1\n",
    "        elif np.all(classification_array == np.array([1, -1, 1, -1, -1, -1])):\n",
    "            class_key = 2\n",
    "        elif np.all(classification_array == np.array([1, 1, -1, -1, -1, -1])):\n",
    "            class_key = 3\n",
    "        elif np.all(classification_array == np.array([1, 1, 1, 1, -1, -1])):\n",
    "            class_key = 4\n",
    "        elif np.all(classification_array == np.array([1, 1, 1, -1, 1, -1])):\n",
    "            class_key = 5\n",
    "        elif np.all(classification_array == np.array([1, 1, 1, -1, -1, 1])):\n",
    "            class_key = 6\n",
    "        else:\n",
    "            class_key = 7\n",
    "\n",
    "        # store tarsi belt orientation classification\n",
    "        tarsi_belt_classification[frame] = class_key\n",
    "        \n",
    "    return tarsi_belt_classification\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the distrbution of x positions \n",
    "\n",
    "Note that only orientation is filtered here (fly can't be upside down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_prob(head, thorax, abdomen, n_slices):\n",
    "    # Range 0 (back of chamber) to 8.929 (front of chamber)\n",
    "    chamber_min_x = 0 # mm\n",
    "    chamber_max_x = 8.929 # mm\n",
    "    pos_length = (chamber_max_x - chamber_min_x)/n_slices\n",
    "    tx = thorax['thorax_x']\n",
    "\n",
    "    # filter walking based on upright orientation... head and abdomen\n",
    "    hz=-head['head_z']\n",
    "    az=-abdomen['abdomen_z']\n",
    "    vertical_diff = az - hz\n",
    "    filt_idxs = np.where(vertical_diff < 0)[0]# fly is upside down\n",
    "    non_filt_idxs = np.setdiff1d(np.arange(0,len(tx)), filt_idxs)\n",
    "\n",
    "    # filter thorax x position based on the fly being upright\n",
    "    filt_tx = tx[non_filt_idxs]\n",
    "\n",
    "    # determine the proportion of instances where the fly is in certain parts of the chamber\n",
    "    start_pos = chamber_min_x\n",
    "    pos_dist = np.zeros(n_slices)\n",
    "    mid_pos = np.zeros(n_slices)\n",
    "    for j in range(n_slices):\n",
    "        end_pos = start_pos + pos_length\n",
    "        mid_pos[j] = start_pos + (pos_length/2) \n",
    "        pos_dist[j] = len(filt_tx[np.logical_and(filt_tx > start_pos, filt_tx < end_pos)])\n",
    "        start_pos = end_pos\n",
    "    pos_dist = pos_dist/np.sum(pos_dist)\n",
    "\n",
    "#     # plot a heatmap\n",
    "#     plt.figure(1, figsize = [10,5])\n",
    "#     plt.plot(mid_pos, pos_dist, color ='k', marker ='.', markersize = 10)\n",
    "#     plt.xlabel('mid point position (mm)', fontsize = 14)\n",
    "#     plt.ylabel('Position Probability', fontsize = 14)\n",
    "#     plt.xticks(fontsize = 12)\n",
    "#     plt.yticks(fontsize = 12)\n",
    "\n",
    "    return pos_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_kinematics(metric, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, fw_stance_start):\n",
    "    # find swing and stance periods during classifier forward walking bouts\n",
    "    fw_bouts = np.where(behavior_classifier==1)[0]\n",
    "    if len(fw_bouts) > 0: # proceed if there is one or more walking bouts\n",
    "        # for each walking bout\n",
    "        diff_classes =  np.diff(fw_bouts)\n",
    "        nbouts = len(np.where(diff_classes>1)[0])+1 # number of forward walking bouts\n",
    "\n",
    "        if nbouts > 1: # multipe forward walking bouts\n",
    "            bout_transitions = np.where(diff_classes>1)[0]\n",
    "            start_bout = fw_bouts[0]\n",
    "            for bout in range(nbouts): # iterate through bouts\n",
    "                if bout == nbouts - 1: # last walking bout\n",
    "                    end_bout = fw_bouts[-1]\n",
    "                else:\n",
    "                    end_bout = fw_bouts[bout_transitions[bout]]\n",
    "\n",
    "#                 print('start - ', start_bout)\n",
    "#                 print('end - ', end_bout)\n",
    "\n",
    "                # for each leg\n",
    "                for l in range(6): #iterate through legs\n",
    "                    # find swing and stance in the forward walking array \n",
    "                    leg_stance = fw_stance_start[l][np.logical_and(fw_stance_start[l]>=start_bout, fw_stance_start[l]<=end_bout)]\n",
    "\n",
    "                    '''filter metric - all metrics are aligned to the start of a step'''\n",
    "                    if len(leg_stance) > 0:\n",
    "                        for j in range(len(leg_stance)): # go through stance indices\n",
    "                            # filter metric based on values of filter metric\n",
    "                            check_1 = np.logical_or(filter_metric[l, leg_stance[j]]<lower_filter_threshold, filter_metric[l, leg_stance[j]]>upper_filter_threshold)\n",
    "                            check_2 = np.isnan(filter_metric[l, leg_stance[j]])\n",
    "                            check_3 = np.logical_or(filter_metric_2[l, leg_stance[j]]<lower_filter_threshold_2, filter_metric_2[l, leg_stance[j]]>upper_filter_threshold_2)\n",
    "                            check_4 = np.isnan(filter_metric_2[l, leg_stance[j]])\n",
    "\n",
    "                            if check_1 or check_2 or check_3 or check_4:\n",
    "                                metric[l, leg_stance[j]] = np.nan # filter the metric\n",
    "\n",
    "                            if j == len(leg_stance)-1: # filter out the right edge case\n",
    "                                metric[l, leg_stance[j]] = np.nan # filter the metric\n",
    "\n",
    "                # update the start of a bout\n",
    "                if bout < nbouts-1:\n",
    "                    start_bout = fw_bouts[bout_transitions[bout]+1]\n",
    "\n",
    "        else: # only one bout\n",
    "            start_bout = fw_bouts[0]\n",
    "            end_bout = fw_bouts[-1]\n",
    "\n",
    "            # for each leg\n",
    "            for l in range(6): #iterate through legs\n",
    "                # find swing and stance in the forward walking array \n",
    "                leg_stance = fw_stance_start[l][np.logical_and(fw_stance_start[l]>=start_bout, fw_stance_start[l]<=end_bout)]\n",
    "\n",
    "                '''filter metric - all metrics are aligned to the start of a step'''\n",
    "                if len(leg_stance) > 0:\n",
    "                    for j in range(len(leg_stance)): # go through stance indices\n",
    "                        # filter metric based on values of filter metric\n",
    "                        check_1 = np.logical_or(filter_metric[l, leg_stance[j]]<lower_filter_threshold, filter_metric[l, leg_stance[j]]>upper_filter_threshold)\n",
    "                        check_2 = np.isnan(filter_metric[l, leg_stance[j]])\n",
    "                        check_3 = np.logical_or(filter_metric_2[l, leg_stance[j]]<lower_filter_threshold_2, filter_metric_2[l, leg_stance[j]]>upper_filter_threshold_2)\n",
    "                        check_4 = np.isnan(filter_metric_2[l, leg_stance[j]])\n",
    "\n",
    "                        if check_1 or check_2 or check_3 or check_4:\n",
    "                            metric[l, leg_stance[j]] = np.nan # filter the metric\n",
    "\n",
    "                        if j == len(leg_stance)-1: # filter out the right edge case\n",
    "                            metric[l, leg_stance[j]] = np.nan # filter the metric\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_phase(metric, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, fw_stance_start):\n",
    "    # find swing and stance periods during classifier forward walking bouts\n",
    "    phase_ref_leg = [3,3,3,3,3,4,4,4,4,5,5,5,0,1]\n",
    "    fw_bouts = np.where(behavior_classifier==1)[0]\n",
    "    if len(fw_bouts) > 0: # proceed if there is one or more walking bouts\n",
    "        # for each walking bout\n",
    "        diff_classes =  np.diff(fw_bouts)\n",
    "        nbouts = len(np.where(diff_classes>1)[0])+1 # number of forward walking bouts\n",
    "\n",
    "        if nbouts > 1: # multipe forward walking bouts\n",
    "            bout_transitions = np.where(diff_classes>1)[0]\n",
    "            start_bout = fw_bouts[0]\n",
    "            for bout in range(nbouts): # iterate through bouts\n",
    "                if bout == nbouts - 1: # last walking bout\n",
    "                    end_bout = fw_bouts[-1]\n",
    "                else:\n",
    "                    end_bout = fw_bouts[bout_transitions[bout]]\n",
    "\n",
    "    #             print('start - ', start_bout)\n",
    "    #             print('end - ', end_bout)\n",
    "\n",
    "                # for each reference leg\n",
    "                phase_cnt = -1\n",
    "                for l in phase_ref_leg: #iterate through legs\n",
    "                    phase_cnt += 1\n",
    "                    # find swing and stance in the forward walking array \n",
    "                    leg_stance = fw_stance_start[l][np.logical_and(fw_stance_start[l]>=start_bout, fw_stance_start[l]<=end_bout)]\n",
    "\n",
    "                    '''filter metric - all metrics are aligned to the start of a step'''\n",
    "                    if len(leg_stance) > 0:\n",
    "                        for j in range(len(leg_stance)): # go through stance indices\n",
    "                            # filter metric based on values of filter metric\n",
    "                            check_1 = np.logical_or(filter_metric[l, leg_stance[j]]<lower_filter_threshold, filter_metric[l, leg_stance[j]]>upper_filter_threshold)\n",
    "                            check_2 = np.isnan(filter_metric[l, leg_stance[j]])\n",
    "                            check_3 = np.logical_or(filter_metric_2[l, leg_stance[j]]<lower_filter_threshold_2, filter_metric_2[l, leg_stance[j]]>upper_filter_threshold_2)\n",
    "                            check_4 = np.isnan(filter_metric_2[l, leg_stance[j]])\n",
    "\n",
    "                            if check_1 or check_2 or check_3 or check_4:\n",
    "                                metric[phase_cnt, leg_stance[j]] = np.nan # filter the metric\n",
    "\n",
    "                            if j == len(leg_stance)-1: # filter out the right edge case\n",
    "                                metric[phase_cnt, leg_stance[j]] = np.nan # filter the metric\n",
    "\n",
    "                # update the start of a bout\n",
    "                if bout < nbouts-1:\n",
    "                    start_bout = fw_bouts[bout_transitions[bout]+1]\n",
    "\n",
    "        else: # only one bout\n",
    "            start_bout = fw_bouts[0]\n",
    "            end_bout = fw_bouts[-1]\n",
    "\n",
    "            # for each leg\n",
    "            phase_cnt = -1\n",
    "            for l in phase_ref_leg: #iterate through legs\n",
    "                phase_cnt += 1\n",
    "                # find swing and stance in the forward walking array \n",
    "                leg_stance = fw_stance_start[l][np.logical_and(fw_stance_start[l]>=start_bout, fw_stance_start[l]<=end_bout)]\n",
    "\n",
    "                '''filter metric - all metrics are aligned to the start of a step'''\n",
    "                if len(leg_stance) > 0:\n",
    "                    for j in range(len(leg_stance)): # go through stance indices\n",
    "                        # filter metric based on values of filter metric\n",
    "                        check_1 = np.logical_or(filter_metric[l, leg_stance[j]]<lower_filter_threshold, filter_metric[l, leg_stance[j]]>upper_filter_threshold)\n",
    "                        check_2 = np.isnan(filter_metric[l, leg_stance[j]])\n",
    "                        check_3 = np.logical_or(filter_metric_2[l, leg_stance[j]]<lower_filter_threshold_2, filter_metric_2[l, leg_stance[j]]>upper_filter_threshold_2)\n",
    "                        check_4 = np.isnan(filter_metric_2[l, leg_stance[j]])\n",
    "\n",
    "                        if check_1 or check_2 or check_3 or check_4:\n",
    "                            metric[phase_cnt, leg_stance[j]] = np.nan # filter the metric\n",
    "\n",
    "                        if j == len(leg_stance)-1: # filter out the right edge case\n",
    "                            metric[phase_cnt, leg_stance[j]] = np.nan # filter the metric\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract info from data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file_info(data_files):\n",
    "    cond_types = ['presplit', 'split', 'postsplit']\n",
    "    # filter out non csv files\n",
    "    temp_store = []\n",
    "    for i in range(len(data_files)):\n",
    "        if data_files[i][-3::] == 'csv':\n",
    "            temp_store.append(data_files[i])\n",
    "    data_files = temp_store\n",
    "    file_ids = np.zeros((len(data_files), 5)) # fly and trial number\n",
    "    for j in range(len(data_files)):\n",
    "        try: \n",
    "            fly_number = int(data_files[j][3:5])\n",
    "\n",
    "        except:\n",
    "            fly_number = int(data_files[j][3:4])\n",
    "\n",
    "#         print('fly number: ', fly_number)\n",
    "        file_ids[j,0] = fly_number\n",
    "\n",
    "        # trial number \n",
    "        try: \n",
    "            trial_number = int(data_files[j][-6:-4])\n",
    "\n",
    "        except: \n",
    "            trial_number = int(data_files[j][-5:-4])\n",
    "\n",
    "#         print('trial number: ', trial_number)\n",
    "        file_ids[j,1] = trial_number\n",
    "\n",
    "        # trial conditions (Left or Right)\n",
    "        # right speed condition\n",
    "        r_cond = data_files[j][8:9]\n",
    "        if r_cond == '_':\n",
    "            r_cond = data_files[j][9:10]\n",
    "\n",
    "        # left speed condition\n",
    "        if r_cond == 'H':\n",
    "            l_cond = 'L'\n",
    "            r_val = 1 # high\n",
    "            l_val = 0 # low\n",
    "        else:\n",
    "            l_cond = 'H'\n",
    "            r_val = 0 # low\n",
    "            l_val = 1 # high\n",
    "\n",
    "\n",
    "#         print('right_speed_condition: ', r_cond)\n",
    "#         print('left_speed_condition: ', l_cond)\n",
    "        file_ids[j,2] = r_val\n",
    "        file_ids[j,3] = l_val\n",
    "    \n",
    "        # classify the trial as presplit/split/postsplit\n",
    "        if data_files[j][-13] == '_': # trial 10 condition\n",
    "            if data_files[j][-22:-13] == 'postsplit':\n",
    "                trial_condition = 2\n",
    "            elif data_files[j][-21:-13] == 'presplit':\n",
    "                trial_condition = 0\n",
    "            else: \n",
    "                trial_condition = 1\n",
    "        else:\n",
    "            if data_files[j][-21:-12] == 'postsplit':\n",
    "                trial_condition = 2\n",
    "            elif data_files[j][-20:-12] == 'presplit':\n",
    "                trial_condition = 0\n",
    "            else: \n",
    "                trial_condition = 1\n",
    "        #         print('trial condition: ', cond_types[trial_condition])\n",
    "        file_ids[j,4] = trial_condition\n",
    "\n",
    "    # convert to integer array\n",
    "    file_ids = file_ids.astype(int)\n",
    "    \n",
    "    return file_ids\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively compute kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir ='H:/.shortcut-targets-by-id/10pxdlRXtzFB-abwDGi0jOGOFFNm3pmFK/Tuthill Lab Shared/manuscripts/treadmill_2023/dryad data/'\n",
    "filename = 'R48A07AD_kir_splitbelt_treadmill_dataset.csv'\n",
    "load_data = pd.read_csv(data_dir + filename)\n",
    "data_files = np.unique(load_data['filename'].values).tolist()\n",
    "ntrials = len(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R48A07AD_kir\n",
      "fly10_RS_H_10_LS_L_10_postsplit_Trial_1.csv\n",
      "fly10_RS_H_10_LS_L_10_postsplit_Trial_10.csv\n",
      "fly10_RS_H_10_LS_L_10_postsplit_Trial_2.csv\n",
      "fly10_RS_H_10_LS_L_10_postsplit_Trial_3.csv\n",
      "fly10_RS_H_10_LS_L_10_postsplit_Trial_4.csv\n",
      "fly10_RS_H_10_LS_L_10_postsplit_Trial_5.csv\n",
      "fly10_RS_H_10_LS_L_10_postsplit_Trial_6.csv\n",
      "fly10_RS_H_10_LS_L_10_postsplit_Trial_7.csv\n",
      "fly10_RS_H_10_LS_L_10_postsplit_Trial_8.csv\n",
      "fly10_RS_H_10_LS_L_10_postsplit_Trial_9.csv\n",
      "fly10_RS_H_10_LS_L_10_presplit_Trial_1.csv\n",
      "fly10_RS_H_10_LS_L_10_presplit_Trial_10.csv\n",
      "fly10_RS_H_10_LS_L_10_presplit_Trial_2.csv\n",
      "fly10_RS_H_10_LS_L_10_presplit_Trial_3.csv\n",
      "fly10_RS_H_10_LS_L_10_presplit_Trial_4.csv\n",
      "fly10_RS_H_10_LS_L_10_presplit_Trial_5.csv\n",
      "fly10_RS_H_10_LS_L_10_presplit_Trial_6.csv\n",
      "fly10_RS_H_10_LS_L_10_presplit_Trial_7.csv\n",
      "fly10_RS_H_10_LS_L_10_presplit_Trial_8.csv\n",
      "fly10_RS_H_10_LS_L_10_presplit_Trial_9.csv\n",
      "fly10_RS_H_12_LS_L_8_split_Trial_1.csv\n",
      "fly10_RS_H_12_LS_L_8_split_Trial_10.csv\n",
      "fly10_RS_H_12_LS_L_8_split_Trial_2.csv\n",
      "fly10_RS_H_12_LS_L_8_split_Trial_3.csv\n",
      "fly10_RS_H_12_LS_L_8_split_Trial_4.csv\n",
      "fly10_RS_H_12_LS_L_8_split_Trial_5.csv\n",
      "fly10_RS_H_12_LS_L_8_split_Trial_6.csv\n",
      "fly10_RS_H_12_LS_L_8_split_Trial_7.csv\n",
      "fly10_RS_H_12_LS_L_8_split_Trial_8.csv\n",
      "fly10_RS_H_12_LS_L_8_split_Trial_9.csv\n",
      "fly10_RS_L_10_LS_H_10_postsplit_Trial_1.csv\n",
      "fly10_RS_L_10_LS_H_10_postsplit_Trial_10.csv\n",
      "fly10_RS_L_10_LS_H_10_postsplit_Trial_2.csv\n",
      "fly10_RS_L_10_LS_H_10_postsplit_Trial_3.csv\n",
      "fly10_RS_L_10_LS_H_10_postsplit_Trial_4.csv\n",
      "fly10_RS_L_10_LS_H_10_postsplit_Trial_5.csv\n",
      "fly10_RS_L_10_LS_H_10_postsplit_Trial_6.csv\n",
      "fly10_RS_L_10_LS_H_10_postsplit_Trial_7.csv\n",
      "fly10_RS_L_10_LS_H_10_postsplit_Trial_8.csv\n",
      "fly10_RS_L_10_LS_H_10_postsplit_Trial_9.csv\n",
      "fly10_RS_L_10_LS_H_10_presplit_Trial_1.csv\n",
      "fly10_RS_L_10_LS_H_10_presplit_Trial_10.csv\n",
      "fly10_RS_L_10_LS_H_10_presplit_Trial_2.csv\n",
      "fly10_RS_L_10_LS_H_10_presplit_Trial_3.csv\n",
      "fly10_RS_L_10_LS_H_10_presplit_Trial_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pratt\\AppData\\Local\\Temp\\ipykernel_3220\\1459166540.py:22: RuntimeWarning: Mean of empty slice\n",
      "  leg_error = np.nanmean((curr_tracked_data[['r1_error', 'r2_error', 'r3_error', 'l1_error', 'l2_error', 'l3_error']].values), axis =1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fly10_RS_L_10_LS_H_10_presplit_Trial_5.csv\n",
      "fly10_RS_L_10_LS_H_10_presplit_Trial_6.csv\n",
      "fly10_RS_L_10_LS_H_10_presplit_Trial_7.csv\n",
      "fly10_RS_L_10_LS_H_10_presplit_Trial_8.csv\n",
      "fly10_RS_L_10_LS_H_10_presplit_Trial_9.csv\n",
      "fly10_RS_L_8_LS_H_12_split_Trial_1.csv\n",
      "fly10_RS_L_8_LS_H_12_split_Trial_10.csv\n",
      "fly10_RS_L_8_LS_H_12_split_Trial_2.csv\n",
      "fly10_RS_L_8_LS_H_12_split_Trial_3.csv\n",
      "fly10_RS_L_8_LS_H_12_split_Trial_4.csv\n",
      "fly10_RS_L_8_LS_H_12_split_Trial_5.csv\n",
      "fly10_RS_L_8_LS_H_12_split_Trial_6.csv\n",
      "fly10_RS_L_8_LS_H_12_split_Trial_7.csv\n",
      "fly10_RS_L_8_LS_H_12_split_Trial_8.csv\n",
      "fly10_RS_L_8_LS_H_12_split_Trial_9.csv\n",
      "fly11_RS_H_10_LS_L_10_postsplit_Trial_1.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03m'''Interlimb coordination'''\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# reltaive phase and distance\u001b[39;00m\n\u001b[1;32m--> 352\u001b[0m step_phase, relative_distance \u001b[38;5;241m=\u001b[39m \u001b[43mrelative_phase_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstance_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_pos_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;66;03m# relative stance start times (L1 is the reference leg)\u001b[39;00m\n\u001b[0;32m    355\u001b[0m leg_relative_stance_onset \u001b[38;5;241m=\u001b[39m compute_relative_stance_onset(stance_start, FS, walking_indices, belt_speed)\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mrelative_phase_distance\u001b[1;34m(stance_start, x_pos, y_pos, z_pos_raw, trial_samples)\u001b[0m\n\u001b[0;32m     18\u001b[0m             dx \u001b[38;5;241m=\u001b[39m x_pos[leg1] \u001b[38;5;241m-\u001b[39m x_pos[leg2]\n\u001b[0;32m     19\u001b[0m             dy \u001b[38;5;241m=\u001b[39m y_pos[leg1] \u001b[38;5;241m-\u001b[39m y_pos[leg2]\n\u001b[1;32m---> 20\u001b[0m             dz \u001b[38;5;241m=\u001b[39m \u001b[43mz_pos_raw\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleg1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mz_pos_raw\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleg2\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     21\u001b[0m             relative_distance[j, stance_start[leg1][i]] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(dx[stance_start[leg1][i]]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m dy[stance_start[leg1][i]]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m dz[stance_start[leg1][i]]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)      \n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_phase, relative_distance\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "FS = 200 # frames per second\n",
    "nlegs = 6 # number of legs\n",
    "n_conditions = 6 # number of conditions L/R splits - presplit, split, postsplit\n",
    "trial_duration = 20 # seconds\n",
    "trial_samples = round(FS * trial_duration) # number of frames\n",
    "all_frames = np.arange(0, trial_samples)\n",
    "cond_types = ['presplit', 'split', 'postsplit']\n",
    "v_adj = 1.725 # belt speed adjustment\n",
    "trial_offset_t = 9 # seconds - more conservative, but see below - determined by looking at belt stimulus records\n",
    "trial_offset_samples = round(trial_offset_t * FS)\n",
    "n_slices = 20 # number of position categories\n",
    "genotype_counter = -1 # counter for specifying the number of flies per genotype\n",
    "percent_walking_threshold = 0.025 # fly is walking 10% of the time\n",
    "\n",
    "'''Specifiy the directory wehere the data from Dryad is located'''\n",
    "data_dir ='Path to data'\n",
    "\n",
    "'''Specify where to save the data'''\n",
    "save_dir ='Path where data will be saved'\n",
    "\n",
    "fly_genotypes = ['R48A07AD_kir', 'R39B11_kir']\n",
    "nflies_genotype = [[1,12], [1,11]]\n",
    "genotype_roll_angles = [17.5, 8.75]\n",
    "genotype_pitch_angles = [0.0, 0.0]\n",
    "genotype_yaw_angles = [0.0, 0.0]\n",
    "genotype_boundary_adjustment = [0.0, 0.0]\n",
    "genotype_boundary_bound = [0.15, 0.15]\n",
    "\n",
    "# iterate through genotypes\n",
    "for genotype in fly_genotypes:\n",
    "    print(genotype)\n",
    "    \n",
    "    # load data\n",
    "    filename = genotype + '_splitbelt_treadmill_dataset.csv'\n",
    "    load_data = pd.read_csv(data_dir + filename)\n",
    "    data_files = np.unique(load_data['filename'].values).tolist()\n",
    "    ntrials = len(data_files)\n",
    "     \n",
    "    # counters\n",
    "    cnt = -1\n",
    "    genotype_counter += 1\n",
    "    \n",
    "    # Euler angles - determined from position of legs in stance\n",
    "    roll_angle = math.radians(genotype_roll_angles[genotype_counter]) \n",
    "    pitch_angle = math.radians(genotype_pitch_angles[genotype_counter]) \n",
    "    yaw_angle = math.radians(genotype_yaw_angles[genotype_counter])\n",
    "\n",
    "    # rotation matrices\n",
    "    Rx = np.matrix([[1, 0, 0], [0, math.cos(roll_angle), -math.sin(roll_angle)], [0, math.sin(roll_angle), math.cos(roll_angle)]])\n",
    "    Ry = np.matrix([[math.cos(pitch_angle), 0, math.sin(pitch_angle)], [0, 1, 0], [-math.sin(pitch_angle), 0, math.cos(pitch_angle)]])\n",
    "    Rz = np.matrix([[math.cos(yaw_angle), -math.sin(yaw_angle), 0], [math.sin(yaw_angle), math.cos(yaw_angle), 0], [0, 0, 1]])\n",
    "    \n",
    "    \n",
    "    '''Declare variable storage parameters'''\n",
    "    # Meta Matrix\n",
    "    meta_mat = np.zeros((ntrials, 8)) \n",
    "    \n",
    "    # Position probability\n",
    "    Position_Distribution = np.zeros((ntrials, n_slices))\n",
    "    \n",
    "    # swing stance matrix\n",
    "    Swing_Stance_Matrix = np.zeros((nlegs, trial_samples, ntrials))\n",
    "    Swing_Stance_Matrix_walking = np.zeros((nlegs, trial_samples, ntrials))\n",
    "    \n",
    "    # limb position data\n",
    "    X_Limb_Position = np.zeros((nlegs, trial_samples, ntrials))\n",
    "    Y_Limb_Position = np.zeros((nlegs, trial_samples, ntrials))\n",
    "    Z_Limb_Position = np.zeros((nlegs, trial_samples, ntrials))\n",
    "    \n",
    "    # Head, Throax, Abdomen positions\n",
    "    Body_Position = np.zeros((9, trial_samples, ntrials))\n",
    "    \n",
    "    # Heading\n",
    "    Heading_Direction = np.empty((ntrials,trial_samples))\n",
    "    Heading_Direction[:] = np.nan  \n",
    "    \n",
    "    # Posture parameters\n",
    "    # Body Height\n",
    "    Body_Height = np.empty((ntrials,trial_samples))\n",
    "    Body_Height[:] = np.nan\n",
    "    \n",
    "    # Body Pitch\n",
    "    Body_Pitch_Store = np.empty((ntrials,trial_samples))\n",
    "    Body_Pitch_Store[:] = np.nan\n",
    "    \n",
    "    # Body Angle\n",
    "    Body_Angle_Store = np.empty((ntrials,trial_samples))\n",
    "    Body_Angle_Store[:] = np.nan\n",
    "    \n",
    "    # Velocity\n",
    "    # Total velocity\n",
    "    Total_Velocity = np.empty((ntrials,trial_samples))\n",
    "    Total_Velocity[:] = np.nan\n",
    "    \n",
    "    # Walking speed parallel to driving axis\n",
    "    Parallel_Velocity = np.empty((ntrials,trial_samples))\n",
    "    Parallel_Velocity[:] = np.nan\n",
    "    \n",
    "    # Walking speed perpendicular to driving axis\n",
    "    Perpendicular_Velocity = np.empty((ntrials,trial_samples))\n",
    "    Perpendicular_Velocity[:] = np.nan\n",
    "    \n",
    "    # Number of Legs in Stance\n",
    "    N_LEGS = np.empty((ntrials,trial_samples))\n",
    "    N_LEGS[:] = np.nan\n",
    "    \n",
    "    # Duration of the number of legs in stance\n",
    "    Duration_LEGS = np.empty((6, trial_samples, ntrials))\n",
    "    Duration_LEGS[:] = np.nan\n",
    "    \n",
    "    # Static Stability and Polygon Area\n",
    "    Static_Stability_Store = np.zeros((ntrials, trial_samples))\n",
    "    Polygon_Area_Store = np.zeros((ntrials, trial_samples))\n",
    "    \n",
    "    # Orientation of tarsi w.r.t to belts\n",
    "    Tarsi_Orientation = np.empty((ntrials,trial_samples))\n",
    "    Tarsi_Orientation[:] = np.nan\n",
    "    \n",
    "    # Behavior classifier \n",
    "    Behavior_Classification_Results = np.zeros((ntrials, trial_samples))\n",
    "    \n",
    "    # Left and Right Tripod Coordination Strength\n",
    "    L_TCS = np.empty((ntrials,trial_samples))\n",
    "    L_TCS[:] = np.nan\n",
    "    \n",
    "    R_TCS = np.empty((ntrials,trial_samples))\n",
    "    R_TCS[:] = np.nan\n",
    "    \n",
    "    ''' forward walking version of posture parameters ''' \n",
    "    N_LEGS_walking = np.empty((ntrials,trial_samples))\n",
    "    N_LEGS_walking[:] = np.nan\n",
    "    \n",
    "    Static_Stability_Store_walking  = np.zeros((ntrials, trial_samples))\n",
    "    Polygon_Area_Store_walking  = np.zeros((ntrials, trial_samples))\n",
    "    \n",
    "    Body_Height_walking = np.empty((ntrials,trial_samples))\n",
    "    Body_Height_walking[:] = np.nan\n",
    "    \n",
    "    '''\n",
    "    Step kinematics\n",
    "    '''\n",
    "    # Swing and stance distances\n",
    "    Swing_Distance_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    Swing_Distance_Store[:] = np.nan\n",
    "    \n",
    "    Stance_Distance_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    Stance_Distance_Store[:] = np.nan\n",
    "    \n",
    "    Step_Distance_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    Step_Distance_Store[:] = np.nan\n",
    "    \n",
    "    # stance duration, swing duration, and duty factor\n",
    "    Swing_Duration_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    Swing_Duration_Store[:] = np.nan\n",
    "    \n",
    "    Stance_Duration_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    Stance_Duration_Store[:] = np.nan\n",
    "    \n",
    "    Duty_Factor_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    Duty_Factor_Store[:] = np.nan\n",
    "    \n",
    "    # step frequency\n",
    "    Step_Frequency_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    Step_Frequency_Store[:] = np.nan\n",
    "    \n",
    "    # Swing Height\n",
    "    Swing_Height_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    Swing_Height_Store[:] = np.nan\n",
    "    \n",
    "    # Swing Linearity\n",
    "    Swing_Linearity_Store = np.empty((nlegs, trial_samples,ntrials))\n",
    "    Swing_Linearity_Store[:] = np.nan\n",
    "    \n",
    "    # Stance, Swing, and Step Speeds\n",
    "    Step_Speed_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    Step_Speed_Store[:] = np.nan\n",
    "    \n",
    "    Stance_Speed_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    Stance_Speed_Store[:] = np.nan\n",
    "    \n",
    "    Swing_Speed_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    Swing_Speed_Store[:] = np.nan\n",
    "    \n",
    "    # AEP and PEP\n",
    "    AEPx_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    AEPx_Store[:] = np.nan\n",
    "    \n",
    "    AEPy_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    AEPy_Store[:] = np.nan\n",
    "    \n",
    "    PEPx_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    PEPx_Store[:] = np.nan\n",
    "    \n",
    "    PEPy_Store = np.empty((nlegs, trial_samples, ntrials))\n",
    "    PEPy_Store[:] = np.nan\n",
    "       \n",
    "    # Phase\n",
    "    Step_Phase_Store = np.empty((17, trial_samples, ntrials))\n",
    "    Step_Phase_Store[:] = np.nan\n",
    "    \n",
    "    Relative_Distance_Store = np.empty((17, trial_samples, ntrials))\n",
    "    Relative_Distance_Store[:] = np.nan\n",
    "    \n",
    "    # relative timing to stance onset\n",
    "    Relative_Stance_Onset_Store = np.empty((5, trial_samples, ntrials))\n",
    "    Relative_Stance_Onset_Store[:] = np.nan\n",
    "    \n",
    "    # iterate through trials\n",
    "    for data_filename in data_files: \n",
    "        print(data_filename)\n",
    "        cnt += 1 # iterate counter\n",
    "\n",
    "        '''Isolate the tracking data for the current trial'''\n",
    "        file_info = find_file_info([data_filename])\n",
    "        tracked_col_names = load_data[load_data['filename']==data_filename].columns.tolist()[7::]\n",
    "        curr_tracked_data = load_data[load_data['filename']==data_filename][tracked_col_names] \n",
    "        \n",
    "        '''Obtain meta data, including belt speed'''\n",
    "        fly = load_data[load_data['filename']==data_filename]['fly number'].values[0]\n",
    "        trial = load_data[load_data['filename']==data_filename]['trial number'].values[0]\n",
    "        split_period = load_data[load_data['filename']==data_filename]['split period'].values[0]\n",
    "        l_speed = split_period = load_data[load_data['filename']==data_filename]['left belt speed (mm/s)'].values[0]\n",
    "        r_speed = split_period = load_data[load_data['filename']==data_filename]['right belt speed (mm/s)'].values[0]\n",
    "        belt_speed = np.max([np.array(l_speed, r_speed)]) # choose max speed\n",
    "\n",
    "        # Anlayze tracked data and extract out body kinematics \n",
    "        # organize the data and normalize the legs relative to the thorax\n",
    "        [head, thorax, abdomen, x_pos, y_pos, z_pos, z_pos_raw, tarsi_pos_chamber, division_value, x_pos_allocentric, y_pos_allocentric]=  org_data(curr_tracked_data, Rx, Ry, Rz)\n",
    "\n",
    "        # Analyze kinematics\n",
    "        # velocity\n",
    "        [lin_vel, filt_vel_parallel, filt_vel_perpendicular, heading_angle] = compute_vel(head, thorax, belt_speed)\n",
    "\n",
    "        # HEADING DIRECTION\n",
    "        Heading_Direction[cnt, :] = heading_angle\n",
    "\n",
    "        # Estimate the flies body length for normalizing spatial metrics\n",
    "        BL = estimate_BL(head, abdomen)\n",
    "\n",
    "        # Store limb positon data - need to normalize by body length\n",
    "        X_Limb_Position[:,:,cnt] = np.array(x_pos)/BL\n",
    "        Y_Limb_Position[:,:,cnt] = np.array(y_pos)/BL\n",
    "        Z_Limb_Position[:,:,cnt] = np.array(z_pos_raw)/BL\n",
    "\n",
    "        # store body information\n",
    "        cat_body_pos = np.transpose(np.hstack((head.values, thorax.values, abdomen.values)))/BL\n",
    "        Body_Position[:,:,cnt] = cat_body_pos\n",
    "\n",
    "        # VELOCITY\n",
    "        Total_Velocity[cnt, 1::] = lin_vel/BL\n",
    "        Parallel_Velocity[cnt, 1::] = filt_vel_parallel/BL\n",
    "        Perpendicular_Velocity[cnt, 1::] = filt_vel_perpendicular/BL\n",
    "\n",
    "        # position probability\n",
    "        pos_dist = position_prob(head, thorax, abdomen, n_slices)\n",
    "        Position_Distribution[cnt, :] = pos_dist\n",
    "\n",
    "        # compute swing stance matrix\n",
    "        swing_stance_mat, stance_start, stance_end = swing_stance_classification(x_pos_allocentric, y_pos_allocentric, FS, nlegs, trial_samples)\n",
    "        Swing_Stance_Matrix[:,:,cnt] = swing_stance_mat\n",
    "\n",
    "        # Number of legs in Stance\n",
    "        nlegs_stance = np.sum(swing_stance_mat, axis = 0)\n",
    "        N_LEGS[cnt, :] = nlegs_stance\n",
    "\n",
    "        # behavior_classifier\n",
    "        behavior_classifier, percent_walking, walking_indices = Behavior_Classification(heading_angle, filt_vel_parallel, head, thorax, abdomen, all_frames, curr_tracked_data, trial_samples, nlegs_stance, trial, trial_offset_samples, x_pos_allocentric, y_pos_allocentric, FS)\n",
    "        Behavior_Classification_Results[cnt, :] = behavior_classifier\n",
    "\n",
    "        # Duration of the number of legs in stance\n",
    "        duration_nlegs = legs_in_stance_duration(nlegs_stance, trial_samples)\n",
    "        Duration_LEGS[:, :, cnt] = duration_nlegs\n",
    "\n",
    "        # static stability\n",
    "        static_stability_posture, polygon_area_posture = compute_static_stability(swing_stance_mat, x_pos, y_pos)\n",
    "        Static_Stability_Store[cnt, :] = static_stability_posture\n",
    "        Polygon_Area_Store[cnt, :] = polygon_area_posture\n",
    "\n",
    "        # Additional posture parameters\n",
    "        body_pitch_posture = calculate_body_pitch(head, thorax)\n",
    "        Body_Pitch_Store[cnt, :] = body_pitch_posture\n",
    "\n",
    "        body_angle_posture = calculate_body_angle(head, thorax, abdomen)\n",
    "        Body_Angle_Store[cnt, :] = body_angle_posture\n",
    "\n",
    "        # Classify the orientation of the tarsi w.r.t the the left and right belts\n",
    "         # Adjust division boundary to correct for genotype-specific reference frame correction\n",
    "        division_value = division_value + genotype_boundary_adjustment[genotype_counter]\n",
    "        boundary_val = genotype_boundary_bound[genotype_counter]\n",
    "        tarsi_belt_classification = tarsi_belt_association(division_value, boundary_val, nlegs, tarsi_pos_chamber)\n",
    "        Tarsi_Orientation[cnt, :] = tarsi_belt_classification\n",
    "\n",
    "        # append fly information to meta matrix \n",
    "        meta_mat[cnt, 0] = fly\n",
    "        meta_mat[cnt, 1] = trial\n",
    "        meta_mat[cnt, 2] = 0 # just determines which split-period occured first which wasn't used later on for analyses # 0: LS occured first, 1: RS occured first\n",
    "        meta_mat[cnt, 3] = file_info[0][2] # 0: LS, 1: RS\n",
    "        meta_mat[cnt, 4] = file_info[0][4] # 0: presplit, 1: split, 2: postsplit\n",
    "        meta_mat[cnt, 5] = belt_speed # driving speed - faster belt chosen during split\n",
    "        meta_mat[cnt, 6] = percent_walking # fraction of trial walking\n",
    "        meta_mat[cnt, 7] = BL # body length\n",
    "\n",
    "        # Portion of time that the fly must be walking to analyze kinematics\n",
    "        if percent_walking >= percent_walking_threshold:\n",
    "\n",
    "            Swing_Stance_Matrix_walking[:,:,cnt] = swing_stance_mat\n",
    "\n",
    "            # body height - posture and walking\n",
    "            bh_walking = comupte_body_height(swing_stance_mat, z_pos, BL)\n",
    "            bh_posture = comupte_body_height(swing_stance_mat, z_pos, BL)\n",
    "            Body_Height[cnt, :] = bh_posture\n",
    "            Body_Height_walking[cnt, :] = bh_walking\n",
    "\n",
    "            # static stability - walking\n",
    "            static_stability_walking, polygon_area_walking = compute_static_stability(swing_stance_mat, x_pos, y_pos)\n",
    "            Static_Stability_Store_walking[cnt, :] = static_stability_walking\n",
    "            Polygon_Area_Store_walking[cnt, :] = polygon_area_walking\n",
    "\n",
    "            # number of legs in stance - walking\n",
    "            nlegs_stance_walking = np.sum(swing_stance_mat, axis = 0)\n",
    "            N_LEGS_walking[cnt, :] = nlegs_stance_walking\n",
    "\n",
    "            # analyze intralimb kinematics and obtain swing stance matrix\n",
    "            # stride length\n",
    "            swing_distance = compute_swing_distance(stance_start, stance_end, x_pos, y_pos, z_pos_raw, BL)\n",
    "            stance_distance = compute_stance_distance(stance_start, stance_end, x_pos, y_pos, z_pos_raw, BL)\n",
    "            step_distance = compute_step_distance(x_pos, y_pos, z_pos_raw, stance_start, stance_end, BL, FS)\n",
    "\n",
    "            # stance and swing duration, and duty factor \n",
    "            stance_duration, swing_duration, duty_factor = swing_stance_duration(stance_start, stance_end)\n",
    "\n",
    "            # step frequency \n",
    "            step_frequency = compute_step_freq(stance_start)\n",
    "\n",
    "            # swing height\n",
    "            swing_height = compute_swing_height(x_pos, y_pos, z_pos_raw, stance_start, stance_end, BL)\n",
    "\n",
    "            # swing linerity\n",
    "            swing_linearity = compute_swing_linearity(x_pos, y_pos, stance_start, stance_end, BL)\n",
    "\n",
    "            # step, stance, speed speeds\n",
    "            step_speed, stance_speed, swing_speed = compute_tarsi_speeds(x_pos, y_pos, z_pos, stance_start, stance_end, BL, FS)\n",
    "\n",
    "            # AEP and PEP\n",
    "            AEPx, AEPy, PEPx, PEPy = compute_AEP_PEP(x_pos, y_pos, stance_start, stance_end, BL)\n",
    "\n",
    "            \n",
    "            '''Interlimb coordination'''\n",
    "            # reltaive phase and distance\n",
    "            step_phase, relative_distance = relative_phase_distance(stance_start, x_pos, y_pos, z_pos_raw, trial_samples)\n",
    "\n",
    "            # relative stance start times (L1 is the reference leg)\n",
    "            leg_relative_stance_onset = compute_relative_stance_onset(stance_start, FS, walking_indices, belt_speed)\n",
    "\n",
    "            # tripod coordination strength\n",
    "            [right_tcs, left_tcs] = tripod_coordination_strength(walking_indices, FS, stance_start, stance_end)\n",
    "\n",
    "            \n",
    "            '''Filter kinematics - right edge case, step frequency, and swing duration'''\n",
    "            # swing duration filtering\n",
    "            lower_filter_threshold = 0.02\n",
    "            upper_filter_threshold = 0.075\n",
    "\n",
    "            filter_metric = swing_duration\n",
    "\n",
    "            # step frequency filter\n",
    "            lower_filter_threshold_2 = 5\n",
    "            upper_filter_threshold_2 = 20\n",
    "\n",
    "            filter_metric_2 = step_frequency\n",
    "\n",
    "            # store intralimb kinematics and interlimb coordination\n",
    "            Swing_Distance_Store[:,:,cnt] = filter_kinematics(swing_distance, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            Stance_Distance_Store[:,:,cnt] = filter_kinematics(stance_distance, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            Step_Distance_Store[:,:,cnt] = filter_kinematics(step_distance, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            Stance_Duration_Store[:,:,cnt] = filter_kinematics(stance_duration, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            Duty_Factor_Store[:,:,cnt] = filter_kinematics(duty_factor, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            Swing_Height_Store[:,:,cnt] = filter_kinematics(swing_height, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            Swing_Linearity_Store[:,:,cnt] = filter_kinematics(swing_linearity, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            Step_Speed_Store[:,:,cnt] = filter_kinematics(step_speed, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            Stance_Speed_Store[:,:,cnt] = filter_kinematics(stance_speed, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            Swing_Speed_Store[:,:,cnt] = filter_kinematics(swing_speed, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            AEPx_Store[:,:,cnt] = filter_kinematics(AEPx, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            AEPy_Store[:,:,cnt] = filter_kinematics(AEPy, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            PEPx_Store[:,:,cnt] = filter_kinematics(PEPx, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            PEPy_Store[:,:,cnt] = filter_kinematics(PEPy, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            Step_Phase_Store[:,:,cnt] = filter_phase(step_phase, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            Relative_Distance_Store[:,:,cnt] = filter_phase(relative_distance, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            Swing_Duration_Store[:,:,cnt] = filter_kinematics(swing_duration, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            Step_Frequency_Store[:,:,cnt] = filter_kinematics(step_frequency, filter_metric, lower_filter_threshold, upper_filter_threshold, filter_metric_2, lower_filter_threshold_2, upper_filter_threshold_2, behavior_classifier, stance_start)\n",
    "            Relative_Stance_Onset_Store[:,:,cnt] = leg_relative_stance_onset\n",
    "            L_TCS[cnt,:] = left_tcs\n",
    "            R_TCS[cnt,:] = right_tcs\n",
    "\n",
    "            '''Uncomment to visualize behavior classifier and swing stance plot of trial(s)'''\n",
    "#             plot_behavior_classification(swing_stance_mat, behavior_classifier, fly, trial, False)\n",
    "\n",
    "'''Uncomment this section to save kinematic results used in the visualization script as numpy files'''\n",
    "#     np.save(save_dir + genotype +'_meta_matrix.npy', meta_mat)\n",
    "#     np.save(save_dir + genotype +'_limb_positions.npy', [X_Limb_Position, Y_Limb_Position, Z_Limb_Position])\n",
    "#     np.save(save_dir + genotype +'_body_positions.npy', Body_Position)\n",
    "#     np.save(save_dir + genotype +'_swing_stance_matrix_posture.npy', Swing_Stance_Matrix)\n",
    "#     np.save(save_dir + genotype +'_swing_stance_matrix_walking.npy', Swing_Stance_Matrix_walking)\n",
    "#     np.save(save_dir + genotype +'_heading_angle.npy', Heading_Direction)\n",
    "#     np.save(save_dir + genotype +'_total_velocity.npy', Total_Velocity)\n",
    "#     np.save(save_dir + genotype +'_parallel_velocity.npy', Parallel_Velocity)\n",
    "#     np.save(save_dir + genotype +'_perpendicular_velocity.npy', Perpendicular_Velocity)\n",
    "#     np.save(save_dir + genotype +'_step_frequency.npy', Step_Frequency_Store)\n",
    "#     np.save(save_dir + genotype +'_swing_distance.npy', Swing_Distance_Store)\n",
    "#     np.save(save_dir + genotype +'_step_distance.npy', Step_Distance_Store)\n",
    "#     np.save(save_dir + genotype +'_stance_distance.npy', Stance_Distance_Store)\n",
    "#     np.save(save_dir + genotype +'_stance_duration.npy', Stance_Duration_Store)\n",
    "#     np.save(save_dir + genotype +'_swing_duration.npy', Swing_Duration_Store)\n",
    "#     np.save(save_dir + genotype +'_duty_factor.npy', Duty_Factor_Store)\n",
    "#     np.save(save_dir + genotype +'_phase.npy', Step_Phase_Store)\n",
    "#     np.save(save_dir + genotype +'_relative_distance.npy', Relative_Distance_Store)\n",
    "#     np.save(save_dir + genotype +'_relative_stance_onset.npy', Relative_Stance_Onset_Store)\n",
    "#     np.save(save_dir + genotype +'_number_legs_in_stance_posture.npy', N_LEGS)\n",
    "#     np.save(save_dir + genotype +'_number_legs_in_stance_walking.npy', N_LEGS_walking)\n",
    "#     np.save(save_dir + genotype +'_legs_in_stance_duration.npy', Duration_LEGS)\n",
    "#     np.save(save_dir + genotype +'_swing_height.npy', Swing_Height_Store)\n",
    "#     np.save(save_dir + genotype +'_swing_linearity.npy', Swing_Linearity_Store)\n",
    "#     np.save(save_dir + genotype +'_body_height_posture.npy', Body_Height)\n",
    "#     np.save(save_dir + genotype +'_body_height_walking.npy', Body_Height_walking)\n",
    "#     np.save(save_dir + genotype +'_body_pitch.npy', Body_Pitch_Store)\n",
    "#     np.save(save_dir + genotype +'_body_angle.npy', Body_Angle_Store)\n",
    "#     np.save(save_dir + genotype +'_static_stability_posture.npy', Static_Stability_Store)\n",
    "#     np.save(save_dir + genotype +'_static_stability_walking.npy', Static_Stability_Store_walking)\n",
    "#     np.save(save_dir + genotype +'_polygon_area_posture.npy', Polygon_Area_Store)\n",
    "#     np.save(save_dir + genotype +'_polygon_area_walking.npy', Polygon_Area_Store_walking)\n",
    "#     np.save(save_dir + genotype +'_right_tcs.npy', R_TCS)\n",
    "#     np.save(save_dir + genotype +'_left_tcs.npy', L_TCS)\n",
    "#     np.save(save_dir + genotype +'_tarsi_classification.npy', Tarsi_Orientation)\n",
    "#     np.save(save_dir + genotype +'_behavior_classification.npy', Behavior_Classification_Results)\n",
    "#     np.save(save_dir + genotype +'_step_speed.npy', Step_Speed_Store)\n",
    "#     np.save(save_dir + genotype +'_stance_speed.npy', Stance_Speed_Store)\n",
    "#     np.save(save_dir + genotype +'_swing_speed.npy', Swing_Speed_Store)\n",
    "#     np.save(save_dir + genotype +'_AEPx.npy', AEPx_Store)\n",
    "#     np.save(save_dir + genotype +'_AEPy.npy', AEPy_Store)\n",
    "#     np.save(save_dir + genotype +'_PEPx.npy', PEPx_Store)\n",
    "#     np.save(save_dir + genotype +'_PEPy.npy', PEPy_Store)\n",
    "#     np.save(save_dir + genotype +'_position_probability.npy', Position_Distribution)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
